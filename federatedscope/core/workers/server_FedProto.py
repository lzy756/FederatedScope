"""
FedProto (Federated Prototypical Learning) Server Implementation

Reference:
FedProto: Federated Prototype Learning across Heterogeneous Clients

Core Functionality:
1. Prototype Aggregation: Aggregate local prototypes from clients
2. Global Prototype Computation: Compute weighted or average global prototypes
3. Prototype Distribution: Broadcast global prototypes to clients
4. Model Aggregation: Standard FedAvg for model parameters
"""

import logging
import torch
from federatedscope.core.workers import Server
from federatedscope.core.message import Message

logger = logging.getLogger(__name__)


class FedProtoServer(Server):
    """
    FedProto Server Implementation

    Responsibilities:
    1. Aggregate local prototypes from clients
    2. Compute global prototypes (mean or weighted mean)
    3. Distribute global prototypes to clients
    4. Perform standard model aggregation (FedAvg)

    Algorithm Flow (each communication round):
    1. Receive model parameters and local prototypes from clients
    2. Aggregate model parameters using FedAvg
    3. Aggregate prototypes to form global prototypes
    4. Broadcast updated model and global prototypes to clients
    """

    def __init__(self,
                 ID=-1,
                 state=0,
                 config=None,
                 data=None,
                 model=None,
                 client_num=5,
                 total_round_num=10,
                 device='cpu',
                 strategy=None,
                 unseen_clients_id=None,
                 **kwargs):
        super(FedProtoServer, self).__init__(
            ID=ID,
            state=state,
            config=config,
            data=data,
            model=model,
            client_num=client_num,
            total_round_num=total_round_num,
            device=device,
            strategy=strategy,
            unseen_clients_id=unseen_clients_id,
            **kwargs
        )

        # FedProto specific parameters
        self.num_classes = config.model.num_classes
        self.embedding_dim = config.fedproto.embedding_dim
        self.aggregation_method = config.fedproto.aggregation_method

        # Storage for received prototypes
        self.received_prototypes = {}  # {client_id: (prototypes, sample_count)}

        # Global prototypes
        self.global_prototypes = None

        logger.info(f"FedProtoServer initialized: num_classes={self.num_classes}, "
                   f"embedding_dim={self.embedding_dim}, "
                   f"aggregation={self.aggregation_method}")

    def check_and_move_on(self,
                         check_eval_result=False,
                         min_received_num=None):
        """
        Override to handle prototype aggregation along with model aggregation

        This method is called when enough clients have responded.
        """
        min_received_num = len(self.comm_manager.get_neighbors().keys()) \
            if min_received_num is None else min_received_num

        if check_eval_result:
            # Check evaluation results (standard behavior)
            minimal_number = min_received_num if self._cfg.federate.mode.lower() == "standalone" \
                else len(self.comm_manager.get_neighbors())

            if self.check_client_join_in() and len(self._outstanding_vals) >= minimal_number:
                # Merge evaluation results
                formatted_eval_res = self.merge_eval_results_from_all_clients()
                self.history_results = self.merge_eval_results(
                    self.history_results, formatted_eval_res, self.state
                )

                if self.mode == 'standalone':
                    self.check_and_save()
                return True

        else:
            # Check training results - this is where we aggregate prototypes
            move_on_flag = self.check_client_join_in()

            if move_on_flag:
                # Aggregate prototypes before moving on
                self.aggregate_prototypes()

                # Standard model aggregation happens in the parent class
                # via the aggregator mechanism

                # Move to next round
                return True

        return False

    def callback_funcs_for_model_para(self, message: Message):
        """
        Override to receive and store local prototypes from clients

        Clients send both model parameters and local prototypes.
        We need to extract and store the prototypes separately.
        """
        # Standard model parameter handling
        round_number = message.state
        sender = message.sender
        content = message.content
        self.sampler.change_state(sender, 'idle')

        # Check if prototypes are included in the message
        # We expect content to be a dict with 'model_para' and 'prototypes' keys
        if isinstance(content, dict) and 'prototypes' in content:
            # Extract prototypes
            prototypes = content['prototypes']
            sample_count = content.get('sample_count', 1)

            # Store prototypes for aggregation
            self.received_prototypes[sender] = (prototypes, sample_count)
            logger.debug(f"Received prototypes from client {sender}, "
                        f"shape={prototypes.shape}, samples={sample_count}")

            # Extract model parameters for standard aggregation
            model_para = content.get('model_para', content)
        else:
            # No prototypes in this message, use content as model_para
            model_para = content
            logger.warning(f"No prototypes received from client {sender}")

        # Call parent's model aggregation logic with just model_para
        # We'll handle this via the aggregator
        if self._cfg.federate.online_aggr:
            # Online aggregation
            self.aggregator.inc(tuple(model_para.values()) if isinstance(model_para, dict) else model_para)
        else:
            # Store for batch aggregation
            self.msg_buffer['train'][round_number].append((sender, model_para))

    def aggregate_prototypes(self):
        """
        Aggregate local prototypes to form global prototypes

        Two aggregation methods:
        1. 'mean': Simple average of all prototypes
        2. 'weighted_mean': Weighted average based on number of samples per client

        Returns:
            torch.Tensor: Global prototypes of shape (num_classes, embedding_dim)
        """
        if len(self.received_prototypes) == 0:
            logger.warning("No prototypes received for aggregation")
            return

        # Collect all prototypes and weights
        all_prototypes = []
        all_weights = []

        for client_id, (prototypes, sample_count) in self.received_prototypes.items():
            # Move to device
            if isinstance(prototypes, torch.Tensor):
                prototypes = prototypes.to(self.device)
            else:
                prototypes = torch.tensor(prototypes, device=self.device)

            all_prototypes.append(prototypes)
            all_weights.append(sample_count)

        # Stack prototypes: (num_clients, num_classes, embedding_dim)
        stacked_prototypes = torch.stack(all_prototypes, dim=0)

        # Aggregate based on method
        if self.aggregation_method == 'mean':
            # Simple average
            self.global_prototypes = stacked_prototypes.mean(dim=0)
            logger.info(f"Aggregated prototypes using simple mean from {len(all_prototypes)} clients")

        elif self.aggregation_method == 'weighted_mean':
            # Weighted average based on sample counts
            weights = torch.tensor(all_weights, dtype=torch.float32, device=self.device)
            weights = weights / weights.sum()  # Normalize

            # Reshape for broadcasting: (num_clients, 1, 1)
            weights = weights.view(-1, 1, 1)

            # Weighted sum
            self.global_prototypes = (stacked_prototypes * weights).sum(dim=0)
            logger.info(f"Aggregated prototypes using weighted mean from {len(all_prototypes)} clients, "
                       f"total samples={sum(all_weights)}")

        else:
            raise ValueError(f"Unknown aggregation method: {self.aggregation_method}")

        # Log statistics
        proto_norm = torch.norm(self.global_prototypes, p=2, dim=1).mean()
        logger.info(f"Global prototypes computed: shape={self.global_prototypes.shape}, "
                   f"avg_norm={proto_norm.item():.4f}")

        # Clear received prototypes for next round
        self.received_prototypes.clear()

    def broadcast_model_para(self,
                            msg_type='model_para',
                            sample_client_num=-1,
                            filter_unseen_clients=True):
        """
        Override to broadcast both model parameters and global prototypes

        Flow:
        1. Determine receiver list
        2. Broadcast global model parameters (FedAvg result)
        3. Additionally broadcast global prototypes
        """
        # Use parent class to broadcast model parameters
        super().broadcast_model_para(
            msg_type=msg_type,
            sample_client_num=sample_client_num,
            filter_unseen_clients=filter_unseen_clients
        )

        # Additionally broadcast global prototypes if available and msg_type is model_para
        if self.global_prototypes is not None and msg_type == 'model_para':
            # Determine receivers (same logic as parent)
            if filter_unseen_clients:
                self.sampler.change_state(self.unseen_clients_id, 'unseen')

            if sample_client_num > 0:
                receiver = self.sampler.sample(size=sample_client_num)
            else:
                receiver = list(self.comm_manager.neighbors.keys())

            self.broadcast_global_prototypes(receiver=receiver)

            if filter_unseen_clients:
                self.sampler.change_state(self.unseen_clients_id, 'seen')

    def broadcast_global_prototypes(self, receiver=None):
        """
        Broadcast global prototypes to clients

        Args:
            receiver: List of client IDs. If None, broadcast to all neighbors.
        """
        if receiver is None:
            receiver = list(self.comm_manager.neighbors.keys())

        if not receiver:
            logger.warning("No receivers available for global prototype broadcast")
            return

        # Send prototypes as a separate message
        self.comm_manager.send(
            Message(msg_type='global_prototypes',
                   sender=self.ID,
                   receiver=receiver,
                   state=self.state,
                   timestamp=self.cur_timestamp,
                   content=self.global_prototypes.detach().cpu())
        )

        logger.debug(f"Broadcast global prototypes to {len(receiver)} clients")
