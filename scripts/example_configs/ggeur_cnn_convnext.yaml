# GGEUR_Clip with CNN Feature Extractor (ConvNeXt-Base)
#
# This configuration uses ConvNeXt-Base as the feature extractor
# instead of CLIP. ConvNeXt is a modern CNN that achieves performance
# comparable to Vision Transformers while being more efficient.
#
# Key Differences from CLIP-based GGEUR_Clip:
# - Uses ConvNeXt-Base (83.8% ImageNet top-1 accuracy)
# - Feature dimension: 1024 (vs 512 for CLIP ViT-B-16)
# - No need for open_clip library (uses torchvision)
# - Same CNN for training and inference (no alignment issues)
#
# Supported CNN backbones:
# - convnext_tiny (768-dim), convnext_small (768-dim)
# - convnext_base (1024-dim, recommended), convnext_large (1536-dim)
# - resnet18 (512-dim), resnet34 (512-dim), resnet50 (2048-dim)
# - efficientnet_b0 (1280-dim), efficientnet_b4 (1792-dim)

# ========== Basic Settings ==========
use_gpu: True
device: 1
seed: 42
verbose: 1

# ========== Federated Learning Settings ==========
federate:
  method: 'ggeur'
  mode: 'standalone'
  client_num: 60  # One client per domain
  total_round_num: 100
  sample_client_num: 0

# ========== Data Settings ==========
data:
  type: 'office-home'
  root: 'OfficeHomeDataset_10072016'
  splits: [0.7, 0.0, 0.3]

dataloader:
  batch_size: 32
  num_workers: 0

# ========== Model Settings ==========
model:
  type: 'ggeur_mlp'
  num_classes: 65

# ========== Training Settings ==========
train:
  local_update_steps: 10
  optimizer:
    type: 'Adam'
    lr: 0.0001

# ========== GGEUR_Clip Specific Settings ==========
ggeur:
  use: True

  # ===== Feature Extractor Mode =====
  # 'clip': Use CLIP ViT model (requires open_clip)
  # 'cnn': Use pretrained CNN (ConvNeXt, ResNet, etc.)
  feature_extractor: 'cnn'

  # ===== CNN Feature Extractor Settings =====
  # Backbone model: convnext_base achieves best balance of accuracy and speed
  cnn_backbone: 'convnext_base'
  # Whether to use ImageNet pretrained weights
  cnn_pretrained: True
  # Freeze backbone during feature extraction (recommended)
  freeze_backbone: True

  # ===== Feature Dimension =====
  # Must match the CNN backbone output dimension:
  # - convnext_base: 1024
  # - convnext_tiny/small: 768
  # - convnext_large: 1536
  # - resnet18/34: 512
  # - resnet50/101: 2048
  embedding_dim: 1024

  # ===== Feature Caching =====
  use_feature_cache: False
  feature_cache_dir: ''  # Auto: next to data.root

  # ===== Feature Augmentation =====
  num_generated_per_sample: 50
  num_generated_per_prototype: 50
  target_size_per_class: 50

  # ===== MLP Classifier =====
  # Use linear classifier for simplicity
  mlp_hidden_dim: 0  # 0 = linear classifier (1024 -> 65)
  mlp_dropout: 0.0

  # ===== Multi-domain Settings =====
  use_cross_client_prototypes: True

  # ===== Training Settings =====
  statistics_round: 0

  # ===== LDS Settings (Optional) =====
  use_lds: True
  lds_alpha: 0.1
  lds_seed: 42

  # ===== Disable other CNN modes =====
  use_cnn_distillation: False
  use_feature_alignment: False
  use_separated_training: False

# ========== Output Settings ==========
outdir: 'exp/ggeur_cnn_convnext'
expname: 'ggeur_cnn_officehome'
