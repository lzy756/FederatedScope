# Cross-Domain Adaptive configuration for Office-Caltech-10
use_gpu: True
device: 0
backend: 'torch'
seed: 123

federate:
  mode: 'standalone'
  client_num: 20
  total_round_num: 300
  sample_client_num: 5
  method: 'cross_domain_adaptive'
  make_global_eval: False
  share_local_model: False
  online_aggr: False

data:
  root: 'data/office_caltech_10'
  type: 'office_caltech'
  splits: [0.8, 0.1, 0.1]
  batch_size: 4
  shuffle: True
  num_workers: 0
  dirichlet_alpha: 0.1

model:
  type: 'cross_domain_adaptive'
  backbone: 'fedlsa_cnn'
  hidden: 512
  num_classes: 10
  dropout: 0.0
  out_channels: 10

train:
  local_update_steps: 4
  batch_or_epoch: 'epoch'
  optimizer:
    type: 'SGD'
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
  scheduler:
    type: 'StepLR'
    step_size: 30
    gamma: 0.1

eval:
  freq: 1
  metrics: ['acc', 'loss']
  best_res_update_round_wise_key: 'test_acc'
  report: ['weighted_avg', 'avg', 'raw']
  split: ['test', 'val']

early_stop:
  patience: 0
  delta: 0.0
  improve_indicator_mode: 'best'

fedlsa:
  use: True
  lambda_com: 0.5
  tau: 0.1
  use_projector: True
  projector_input_dim: 512
  projector_output_dim: 128
  share_projector: True
  alpha_sep: 0.6
  anchor_train_epochs: 5
  anchor_lr: 0.001

ondemfl:
  enable: True
  pretrain_rounds: 150
  ondemand_rounds: 150
  subset_size: 10
  weight_scheme: 'ratio_times_size'
  min_ratio: 1e-4
  nnls_max_iter: 500
  nnls_tol: 1e-9
  dp_loss: 'kl'
  freeze_predictor_after_stage1: True
  dp_optimizer:
    type: 'SGD'
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.0
    nesterov: False
  grad_layer: ''
  log_metrics: True
  target_distribution: []

cross_domain_adaptive:
  anchor_reweight: True
  anchor_weight_momentum: 0.6
  anchor_weight_eps: 1e-3

trainer:
  type: 'cross_domain_adaptive'

criterion:
  type: 'CrossEntropyLoss'

grad:
  grad_clip: 5.0


# verbose: 1
# print_decimal_digits: 6
