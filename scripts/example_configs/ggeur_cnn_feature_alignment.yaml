# GGEUR_Clip with CNN Feature Alignment - Office-Home LDS
# This configuration trains CNN FROM SCRATCH by aligning features with CLIP
#
# Key Differences from Knowledge Distillation:
# 1. CNN is initialized with random weights (no pretrained)
# 2. CNN learns by aligning features with CLIP features, not soft labels
# 3. Optional: Also align with global prototypes for better cross-domain generalization
#
# Training flow:
# 1. Extract CLIP features and compute local statistics (Round 0)
# 2. Server aggregates covariances and computes global prototypes
# 3. Clients perform feature augmentation and train MLP
# 4. Clients train CNN from scratch with feature alignment loss:
#    L = CE(CNN(x), y) + lambda * MSE(proj(CNN_feat), CLIP_feat)
#    Optional: L += lambda_proto * MSE(proj(CNN_feat), prototype[y])

# ========== Basic Settings ==========
use_gpu: True
device: 0
seed: 42
verbose: 1

# ========== Federated Learning Settings ==========
federate:
  method: 'ggeur'
  mode: 'standalone'
  client_num: 4  # One client per domain
  total_round_num: 100  # More rounds for from-scratch training
  sample_client_num: 4

# ========== Data Settings ==========
data:
  type: 'office-home'
  root: 'OfficeHomeDataset_10072016'
  splits: [0.7, 0.0, 0.3]

dataloader:
  batch_size: 32
  num_workers: 0

# ========== Model Settings ==========
model:
  type: 'ggeur_mlp'
  num_classes: 65

# ========== Training Settings ==========
train:
  local_update_steps: 10
  optimizer:
    type: 'Adam'
    lr: 0.001

# ========== GGEUR_Clip Specific Settings ==========
ggeur:
  use: True

  # CLIP Feature Extraction
  clip_model: 'ViT-B-16'
  clip_pretrained: 'openai'
  clip_model_path: '/root/model/open_clip_vitb16.bin'  # Local path to CLIP weights
  embedding_dim: 512

  # Feature Caching
  use_feature_cache: True
  feature_cache_dir: ''

  # Feature Augmentation (for MLP training)
  num_generated_per_sample: 50
  num_generated_per_prototype: 50
  target_size_per_class: 50

  # MLP Classifier
  mlp_hidden_dim: 0
  mlp_dropout: 0.0

  # Multi-domain Settings
  use_cross_client_prototypes: True

  # Training Settings
  statistics_round: 0

  # LDS Settings (Label Distribution Skew)
  use_lds: True
  lds_alpha: 0.1
  lds_seed: 42

  # ========== CNN Feature Alignment Settings ==========
  # Enable feature alignment mode (NOT distillation)
  use_feature_alignment: True
  use_cnn_distillation: False  # Make sure this is False

  # CNN model architecture
  cnn_model: 'resnet18'  # Options: resnet18, resnet34, resnet50, mobilenet_v2
  # NOTE: pretrained is ignored when use_feature_alignment=True (always from scratch)

  # Feature alignment parameters
  align_weight: 1.0  # Lambda for feature alignment loss
  use_prototype_alignment: True  # Also align with global prototypes
  prototype_align_weight: 0.5  # Lambda for prototype alignment loss

  # CNN training settings
  cnn_lr: 0.01  # Learning rate for CNN
  cnn_local_epochs: 10  # Local epochs for CNN training per round
  cnn_warmup_rounds: 5  # Skip CNN training in first N rounds (wait for MLP and prototypes)

# ========== Output Settings ==========
outdir: 'exp/ggeur_cnn_feature_alignment'
expname: 'ggeur_feature_align_resnet18'
