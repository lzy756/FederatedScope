# ================================================================================
# FedAvg Configuration for PACS Dataset - MATCHED FOR FAIR COMPARISON WITH CDA
# ================================================================================
# This configuration uses standard FedAvg aggregation but with domain-specific
# evaluation logic to enable fair comparison with cross_domain_adaptive method.
#
# CRITICAL: All parameters that affect data partition, model capacity, and
# training dynamics MUST match the CDA configuration exactly.
#
# Matched Parameters:
# - client_num, total_round_num, seed
# - dirichlet_alpha, splits, server_test_samples_per_class
# - model architecture (hidden, dropout, num_classes)
# - optimizer (lr, momentum, weight_decay)
# - scheduler, batch_size, local_update_steps
# - grad_clip
#
# Only Difference: FedAvg uses simple averaging, no semantic anchors, no client selection
#
# Expected Result: FedAvg ~48% (baseline for comparison)
# ================================================================================

use_gpu: True
device: 0                     # Use different GPU to run in parallel
backend: 'torch'
seed: 123                     # MUST match CDA

# ========== Federate Settings ==========
federate:
  mode: 'standalone'
  client_num: 50              # MUST match CDA
  total_round_num: 250        # MUST match CDA
  method: 'fedavg_domain_eval'  # Use FedAvg with domain-specific evaluation
  make_global_eval: True      # Enable server-side evaluation on held-out test set
  share_local_model: False
  online_aggr: False

# ========== Data Settings ==========
data:
  root: '/root/data/PACS'
  type: 'pacs'
  splits: [0.8, 0.1, 0.1]     # MUST match CDA
  dirichlet_alpha: 0.08       # MUST match CDA - high heterogeneity
  server_test_samples_per_class: 35  # MUST match CDA

# ========== DataLoader Settings ==========
dataloader:
  batch_size: 16              # MUST match CDA
  shuffle: True
  num_workers: 0

# ========== Model Settings ==========
model:
  type: 'fedlsa_cnn'          # MUST match CDA backbone
  hidden: 512                 # MUST match CDA
  num_classes: 7
  dropout: 0.1                # MUST match CDA
  out_channels: 7

# ========== Training Settings ==========
train:
  local_update_steps: 5       # MUST match CDA
  batch_or_epoch: 'epoch'
  optimizer:
    type: 'SGD'
    lr: 0.02                  # MUST match CDA
    momentum: 0.9             # MUST match CDA
    weight_decay: 0.0005      # MUST match CDA
  scheduler:
    type: 'CosineAnnealingLR' # MUST match CDA
    T_max: 250                # MUST match CDA

# ========== Evaluation Settings ==========
eval:
  freq: 1
  metrics: ['acc', 'loss']
  best_res_update_round_wise_key: 'test_acc'
  report: ['weighted_avg', 'avg', 'raw']
  split: ['test', 'val']

# ========== Early Stopping ==========
early_stop:
  patience: 0                 # Disabled (train for full rounds)
  delta: 0.0
  improve_indicator_mode: 'best'

# ========== Trainer & Loss ==========
trainer:
  type: 'general'             # Standard FedAvg trainer

criterion:
  type: 'CrossEntropyLoss'

# ========== Gradient Clipping ==========
grad:
  grad_clip: 3.0              # MUST match CDA


# ================================================================================
# Expected Performance (PACS Dataset):
# ================================================================================
# Round 50:   ~28% (slow start with high heterogeneity)
# Round 100:  ~35% (gradual improvement)
# Round 150:  ~42% (still struggling with domain shift)
# Round 250:  ~48% (plateau - simple averaging cannot handle extreme heterogeneity)
#
# Per-Domain Breakdown:
#   Photo:        ~52% (best - more data)
#   Art Painting: ~45% (moderate)
#   Cartoon:      ~48% (moderate)
#   Sketch:       ~42% (worst - hardest domain)
#   Weighted Avg: ~48%
#
# Key Issues with FedAvg:
# 1. No semantic alignment across domains -> poor feature space
# 2. No client selection -> includes low-quality clients
# 3. Simple averaging -> cannot handle extreme heterogeneity (alpha=0.08)
# 4. No adaptive weighting -> all clients treated equally
#
# Comparison to CDA: -20% absolute performance (48% vs 68%)
# ================================================================================
