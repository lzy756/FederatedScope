# FedAvg Baseline with CLIP Features (No GGEUR_Clip Augmentation)
# This is a fair comparison baseline for GGEUR_Clip:
# - Uses same CLIP features extraction
# - Uses same MLP classifier
# - Uses FedAvg aggregation
# - NO data augmentation (uses original imbalanced data)

# ========== Basic Settings ==========
use_gpu: True
device: 1
seed: 42
verbose: 1

# ========== Federated Learning Settings ==========
federate:
  method: 'ggeur'  # Use GGEUR_Clip infrastructure for CLIP feature extraction
  mode: 'standalone'
  client_num: 12  # 4 domains x 3 clients per domain
  total_round_num: 50
  sample_client_num: 12

# ========== Data Settings ==========
data:
  type: 'office-home'
  root: 'OfficeHomeDataset_10072016'
  splits: [0.7, 0.0, 0.3]  # train, val, test ratios (same as GGEUR_Clip)

dataloader:
  batch_size: 16
  num_workers: 0

# ========== Model Settings ==========
model:
  type: 'ggeur_mlp'
  num_classes: 65

# ========== Training Settings ==========
train:
  local_update_steps: 1
  optimizer:
    type: 'Adam'
    lr: 0.001

# ========== GGEUR_Clip Settings (Minimal - No Augmentation) ==========
ggeur:
  use: True

  # CLIP Feature Extraction (same as GGEUR_Clip)
  clip_model: 'ViT-B-16'
  clip_pretrained: 'openai'
  clip_model_path: '/root/model/open_clip_vitb16.bin'
  embedding_dim: 512

  # Feature Caching
  use_feature_cache: True
  feature_cache_dir: ''

  # === KEY DIFFERENCE: No Augmentation ===
  # Set these to 0 to disable data generation
  num_generated_per_sample: 0
  num_generated_per_prototype: 0
  # Set target_size to 0 to use ALL original samples without augmentation
  target_size_per_class: 0

  # MLP Classifier (same as GGEUR_Clip)
  mlp_hidden_dim: 0
  mlp_dropout: 0.0

  # Disable cross-client prototype sharing
  use_cross_client_prototypes: False

  # Training Settings
  statistics_round: 0

# ========== Output Settings ==========
outdir: 'exp/fedavg_officehome_clip_baseline'
expname: 'fedavg_clip_no_augmentation'
