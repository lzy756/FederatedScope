# FedLSA Low Memory Configuration for Server Deployment
# Optimized to prevent OOM kills

# Basic FL settings
use_gpu: True
device: 0
backend: 'torch'
seed: 123

# Federate settings - REDUCED CLIENT NUM
federate:
  mode: 'standalone'
  client_num: 20          # REDUCED from 100 to 20
  total_round_num: 50
  sample_client_num: 3    # REDUCED from 5 to 3
  method: 'fedlsa'
  make_global_eval: False
  share_local_model: False
  online_aggr: False

# Data settings - REDUCED BATCH SIZE
data:
  root: '/home/liziyu/data/office_caltech_10'
  type: 'office_caltech'
  splits: [0.8, 0.1, 0.1]
  batch_size: 4           # REDUCED from 8 to 4
  shuffle: True
  num_workers: 0          # Keep 0 to avoid multiprocessing memory overhead
  dirichlet_alpha: 0.5

# Model settings
model:
  type: 'fedlsa_cnn'
  hidden: 512
  num_classes: 10
  dropout: 0.0
  out_channels: 10

# Training settings
train:
  local_update_steps: 4
  batch_or_epoch: 'epoch'
  optimizer:
    type: 'SGD'
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
  scheduler:
    type: 'StepLR'
    step_size: 30
    gamma: 0.1

# Evaluation settings
eval:
  freq: 10
  metrics: ['acc', 'loss']
  best_res_update_round_wise_key: 'test_acc'
  report: ['weighted_avg', 'avg', 'raw']
  split: ['test', 'val']

# Early stopping
early_stop:
  patience: 50
  delta: 0.0
  improve_indicator_mode: 'best'

# FedLSA specific settings - MEMORY OPTIMIZED
fedlsa:
  use: True

  # Client-side parameters
  lambda_com: 0.5
  tau: 0.1
  use_projector: True
  projector_input_dim: 512
  projector_output_dim: 64   # REDUCED from 128 to 64
  share_projector: True

  # Server-side parameters - REDUCED ANCHOR TRAINING
  alpha_sep: 0.6
  anchor_train_epochs: 5     # REDUCED from 10 to 5
  anchor_lr: 0.001

# Trainer type
trainer:
  type: 'fedlsa_trainer'

# Output directory
outdir: 'exp_fedlsa/office_caltech_lowmem'
expname: 'fedlsa_lowmem'

# Criterion
criterion:
  type: 'CrossEntropyLoss'

# Regularizer
regularizer:
  type: ''
  mu: 0.0

# Gradient - ADD GRADIENT CLIPPING
grad:
  grad_clip: 1.0           # REDUCED from 5.0 to 1.0

# Logging
verbose: 1
print_decimal_digits: 6

