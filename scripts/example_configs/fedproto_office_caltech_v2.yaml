# FedProto Configuration for Domain-Skewed Federated Learning
# Dataset: Office-Caltech-10 (4 domains: Amazon, Webcam, DSLR, Caltech)
# Method: FedProto (Federated Prototype Learning)

# Basic settings
use_gpu: True
device: 0
backend: 'torch'
seed: 123

# Federate settings
federate:
  mode: 'standalone'
  client_num: 20  # Total clients (distributed across 4 domains)
  total_round_num: 100
  sample_client_num: 5
  method: 'fedavg'  # Base aggregation method
  make_global_eval: False
  share_local_model: True  # Share model parameters
  online_aggr: False

# Data settings
data:
  root: '/home/liziyu/data/office_caltech_10'
  type: 'office_caltech'
  splits: [0.8, 0.1, 0.1]  # train, val, test
  batch_size: 4
  shuffle: True
  num_workers: 0  # 设为0避免"too many open files"错误
  dirichlet_alpha: 0.1  # Control non-IID level

# Dataloader settings
dataloader:
  type: 'base'
  batch_size: 4
  shuffle: True
  num_workers: 0  # 设为0避免"too many open files"错误

# Model settings
model:
  type: 'fedlsa_cnn'  # Use same architecture as FedLSA for comparison
  hidden: 512
  num_classes: 10
  dropout: 0.0
  out_channels: 10

# Training settings
train:
  local_update_steps: 4
  batch_or_epoch: 'epoch'
  optimizer:
    type: 'SGD'
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
  scheduler:
    type: 'StepLR'
    step_size: 30
    gamma: 0.1

# Evaluation settings
eval:
  freq: 10
  metrics: ['acc', 'loss']
  best_res_update_round_wise_key: 'test_acc'
  report: ['weighted_avg', 'avg', 'raw']
  split: ['test', 'val']

# Early stopping
early_stop:
  patience: 50
  delta: 0.0
  improve_indicator_mode: 'best'

# FedProto specific settings
fedproto:
  use: True

  # Prototype loss weight (λ in L_total = L_CE + λ * L_proto)
  proto_weight: 1.0

  # Embedding dimension (should match model.hidden)
  embedding_dim: 512

  # Projection layer settings
  use_projector: True
  projector_hidden_dim: 256

  # Distance metric: 'euclidean' or 'cosine'
  distance_metric: 'cosine'

  # Temperature parameter for cosine distance
  temperature: 0.1

  # Aggregation method: 'mean' or 'weighted_mean'
  aggregation_method: 'weighted_mean'

  # Local prototype update epochs
  local_proto_epochs: 1

  # Normalize prototypes to unit sphere
  normalize_prototypes: True

  # Whether to freeze backbone during training
  freeze_backbone: False

# Trainer type
trainer:
  type: 'fedproto_trainer'

# Output directory
outdir: 'exp_fedproto/office_caltech'
expname: 'fedproto_baseline'

# Criterion
criterion:
  type: 'CrossEntropyLoss'

# Regularizer (not used in FedProto)
regularizer:
  type: ''
  mu: 0.0

# Gradient settings
grad:
  grad_clip: 5.0

# Logging
verbose: 1
print_decimal_digits: 6


