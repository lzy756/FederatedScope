# FedProto Configuration for Office-Caltech-10
# Variant: Strong Prototype Regularization
# Best for: Highly heterogeneous data

use_gpu: True
device: 0
backend: 'torch'
seed: 123

federate:
  mode: 'standalone'
  client_num: 50
  total_round_num: 100
  sample_client_num: 10
  method: 'fedavg'
  make_global_eval: False
  share_local_model: True
  online_aggr: False

data:
  root: '/home/liziyu/data/office_caltech_10'
  type: 'office_caltech'
  splits: [0.8, 0.1, 0.1]
  batch_size: 8
  shuffle: True
  num_workers: 4
  dirichlet_alpha: 0.5

dataloader:
  type: 'base'
  batch_size: 8
  shuffle: True
  num_workers: 4

model:
  type: 'fedlsa_cnn'
  hidden: 512
  num_classes: 10
  dropout: 0.0
  out_channels: 10

train:
  local_update_steps: 5
  batch_or_epoch: 'epoch'
  optimizer:
    type: 'SGD'
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.0005
  scheduler:
    type: 'StepLR'
    step_size: 30
    gamma: 0.1

eval:
  freq: 10
  metrics: ['acc', 'loss']
  best_res_update_round_wise_key: 'test_acc'
  report: ['weighted_avg', 'avg', 'raw']
  split: ['test', 'val']

early_stop:
  patience: 50
  delta: 0.0
  improve_indicator_mode: 'best'

fedproto:
  use: True
  proto_weight: 2.0  # Stronger prototype regularization
  embedding_dim: 512
  use_projector: True
  projector_hidden_dim: 256
  distance_metric: 'cosine'
  temperature: 0.05  # Lower temperature for sharper distribution
  aggregation_method: 'weighted_mean'
  local_proto_epochs: 1
  normalize_prototypes: True
  freeze_backbone: False

trainer:
  type: 'fedproto_trainer'

outdir: 'exp_fedproto/office_caltech'
expname: 'fedproto_strong_reg'

criterion:
  type: 'CrossEntropyLoss'

regularizer:
  type: ''
  mu: 0.0

grad:
  grad_clip: 5.0

verbose: 1
print_decimal_digits: 6
