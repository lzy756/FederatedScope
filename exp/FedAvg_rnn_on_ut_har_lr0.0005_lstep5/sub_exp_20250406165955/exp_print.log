2025-04-06 16:59:55,618 (logging:124) INFO: the current machine is at 10.29.59.202
2025-04-06 16:59:55,619 (logging:126) INFO: the current dir is C:\Users\TingNobody\FL\FederatedScope
2025-04-06 16:59:55,619 (logging:127) INFO: the output dir is exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
2025-04-06 16:59:56,753 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:56,754 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:56,779 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.0
  type: 
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:56,922 (utils:147) INFO: The device information file is not provided
2025-04-06 16:59:56,936 (fed_runner:173) INFO: Server has been set up ... 
2025-04-06 16:59:56,940 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:56,991 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,024 (fed_runner:225) INFO: Client 1 has been set up ... 
2025-04-06 16:59:57,027 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,044 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,078 (fed_runner:225) INFO: Client 2 has been set up ... 
2025-04-06 16:59:57,081 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,099 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,129 (fed_runner:225) INFO: Client 3 has been set up ... 
2025-04-06 16:59:57,132 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,150 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,181 (fed_runner:225) INFO: Client 4 has been set up ... 
2025-04-06 16:59:57,184 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,201 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,231 (fed_runner:225) INFO: Client 5 has been set up ... 
2025-04-06 16:59:57,233 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,251 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,283 (fed_runner:225) INFO: Client 6 has been set up ... 
2025-04-06 16:59:57,285 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,301 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,331 (fed_runner:225) INFO: Client 7 has been set up ... 
2025-04-06 16:59:57,334 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,353 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,388 (fed_runner:225) INFO: Client 8 has been set up ... 
2025-04-06 16:59:57,392 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,421 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,454 (fed_runner:225) INFO: Client 9 has been set up ... 
2025-04-06 16:59:57,457 (cfg_fl_setting:173) WARNING: Users specify both valid sample_client_rate as 1.0 and sample_client_num as 10.
		We will use the sample_client_rate value to calculate the actual number of participated clients as 10.
2025-04-06 16:59:57,475 (config:243) INFO: the used configs are: 
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.8, 0.1, 0.1]
  splitter: lda
  splitter_args: [{'alpha': 0.1}]
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: ut_har
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 32
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 10
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: True
  freq: 1
  metrics: ['acc', 'loss']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['test', 'val']
expname: FedAvg_rnn_on_ut_har_lr0.0005_lstep5
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_num: 10
  data_weighted_aggr: False
  ignore_weight: False
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 10
  sample_client_rate: 1.0
  sampler: uniform
  save_to: 
  share_local_model: False
  total_round_num: 500
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  mu: 0.5
  use: True
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: 5.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 7
  pretrain_tasks: []
  stage: 
  task: node
  type: rnn
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp\FedAvg_rnn_on_ut_har_lr0.0005_lstep5\sub_exp_20250406165955
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 5
  lr: 0.0005
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.5
  type: proximal_regularizer
seed: 12345
sgdmf:
  use: False
train:
  batch_or_epoch: epoch
  data_para_dids: []
  local_update_steps: 5
  optimizer:
    lr: 0.0005
    type: Adam
    weight_decay: 0.01
  scheduler:
    type: 
    warmup_ratio: 0.0
trainer:
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: general
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-04-06 16:59:57,506 (fed_runner:225) INFO: Client 10 has been set up ... 
2025-04-06 16:59:57,506 (trainer:345) INFO: Model meta-info: <class 'federatedscope.contrib.model.rnn.UT_HAR_RNN'>.
2025-04-06 16:59:57,506 (trainer:353) INFO: Num of original para names: 6.
2025-04-06 16:59:57,507 (trainer:354) INFO: Num of original trainable para names: 6.
2025-04-06 16:59:57,507 (trainer:356) INFO: Num of preserved para names in local update: 6. 
Preserved para names in local update: {'rnn.bias_ih_l0', 'rnn.weight_hh_l0', 'rnn.weight_ih_l0', 'fc.bias', 'fc.weight', 'rnn.bias_hh_l0'}.
2025-04-06 16:59:57,507 (trainer:360) INFO: Num of filtered para names in local update: 0. 
Filtered para names in local update: set().
2025-04-06 16:59:57,508 (trainer:365) INFO: After register default hooks,
	the hooks_in_train is:
	{
	  "on_fit_start": [
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init",
	    "_hook_on_fit_start_calculate_model_size",
	    "_hook_record_initialization"
	  ],
	  "on_epoch_start": [
	    "_hook_on_epoch_start"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward",
	    "_hook_on_batch_forward_regularizer",
	    "_hook_on_batch_forward_flop_count"
	  ],
	  "on_batch_backward": [
	    "_hook_on_batch_backward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_del_initialization"
	  ]
	};
	the hooks_in_eval is:
            t{
	  "on_fit_start": [
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init",
	    "_hook_record_initialization"
	  ],
	  "on_epoch_start": [
	    "_hook_on_epoch_start"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_del_initialization"
	  ]
	}
2025-04-06 16:59:57,519 (server:843) INFO: ----------- Starting training (Round #0) -------------
2025-04-06 17:00:01,563 (client:354) INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.954877, 'train_total': 2265, 'train_acc': 0.693598, 'train_loss': 2162.796856}}
2025-04-06 17:00:02,461 (client:354) INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.1235, 'train_total': 2560, 'train_acc': 0.582031, 'train_loss': 2876.160093}}
2025-04-06 17:00:02,909 (client:354) INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.226556, 'train_total': 1435, 'train_acc': 0.588153, 'train_loss': 1760.108395}}
2025-04-06 17:00:04,896 (client:354) INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.84295, 'train_total': 6420, 'train_acc': 0.597508, 'train_loss': 5411.740828}}
2025-04-06 17:00:05,095 (client:354) INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.053818, 'train_total': 555, 'train_acc': 0.843243, 'train_loss': 584.869234}}
2025-04-06 17:00:05,262 (client:354) INFO: {'Role': 'Client #10', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.363992, 'train_total': 420, 'train_acc': 0.654762, 'train_loss': 572.876739}}
2025-04-06 17:00:05,461 (client:354) INFO: {'Role': 'Client #9', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.335073, 'train_total': 615, 'train_acc': 0.671545, 'train_loss': 821.069932}}
2025-04-06 17:00:05,613 (client:354) INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.338733, 'train_total': 390, 'train_acc': 0.697436, 'train_loss': 522.105812}}
2025-04-06 17:00:06,823 (client:354) INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_avg_loss': 1.093923, 'train_total': 3865, 'train_acc': 0.584994, 'train_loss': 4228.014074}}
2025-04-06 17:00:07,259 (client:354) INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.991783, 'train_total': 1360, 'train_acc': 0.674265, 'train_loss': 1348.824295}}
2025-04-06 17:00:07,261 (server:353) INFO: Server: Starting evaluation at the end of round 0.
2025-04-06 17:00:07,262 (server:359) INFO: ----------- Starting a new training round (Round #1) -------------
2025-04-06 17:00:07,618 (client:354) INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.5719, 'train_total': 390, 'train_acc': 0.510256, 'train_loss': 613.040959}}
2025-04-06 17:00:08,298 (client:354) INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.986428, 'train_total': 2265, 'train_acc': 0.661369, 'train_loss': 2234.259745}}
2025-04-06 17:00:08,699 (client:354) INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.179757, 'train_total': 1435, 'train_acc': 0.582578, 'train_loss': 1692.95139}}
2025-04-06 17:00:10,532 (client:354) INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.788276, 'train_total': 6420, 'train_acc': 0.598131, 'train_loss': 5060.732345}}
2025-04-06 17:00:10,671 (client:354) INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.406262, 'train_total': 420, 'train_acc': 0.566667, 'train_loss': 590.630053}}
2025-04-06 17:00:10,858 (client:354) INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.12131, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 689.60552}}
2025-04-06 17:00:11,973 (client:354) INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.048841, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 4053.770991}}
2025-04-06 17:00:12,156 (client:354) INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.641433, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 355.995439}}
2025-04-06 17:00:12,875 (client:354) INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.132933, 'train_total': 2560, 'train_acc': 0.564453, 'train_loss': 2900.307993}}
2025-04-06 17:00:13,280 (client:354) INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.016749, 'train_total': 1360, 'train_acc': 0.642647, 'train_loss': 1382.778287}}
2025-04-06 17:00:13,283 (server:615) INFO: {'Role': 'Server #', 'Round': 0, 'Results_weighted_avg': {'test_avg_loss': 1.818899, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 152.823415, 'val_avg_loss': 1.816505, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 153.033858}, 'Results_avg': {'test_avg_loss': 1.910872, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 90.944969, 'val_avg_loss': 1.920745, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 90.098626}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.408097, 'test_avg_loss_bottom_decile': 1.485091, 'test_avg_loss_top_decile': 2.532955, 'test_avg_loss_min': 1.266783, 'test_avg_loss_max': 2.532955, 'test_avg_loss_bottom10%': 1.266783, 'test_avg_loss_top10%': 2.532955, 'test_avg_loss_cos1': 0.977946, 'test_avg_loss_entropy': 2.279459, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 70.812757, 'test_loss_bottom_decile': 21.088291, 'test_loss_top_decile': 236.129547, 'test_loss_min': 16.468179, 'test_loss_max': 236.129547, 'test_loss_bottom10%': 16.468179, 'test_loss_top10%': 236.129547, 'test_loss_cos1': 0.789025, 'test_loss_entropy': 1.995605, 'val_avg_loss_std': 0.399066, 'val_avg_loss_bottom_decile': 1.499376, 'val_avg_loss_top_decile': 2.488478, 'val_avg_loss_min': 1.260951, 'val_avg_loss_max': 2.488478, 'val_avg_loss_bottom10%': 1.260951, 'val_avg_loss_top10%': 2.488478, 'val_avg_loss_cos1': 0.979091, 'val_avg_loss_entropy': 2.28056, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 71.0463, 'val_loss_bottom_decile': 22.884633, 'val_loss_top_decile': 239.900082, 'val_loss_min': 17.653313, 'val_loss_max': 239.900082, 'val_loss_bottom10%': 17.653313, 'val_loss_top10%': 239.900082, 'val_loss_cos1': 0.78524, 'val_loss_entropy': 1.994499}}
2025-04-06 17:00:13,287 (server:353) INFO: Server: Starting evaluation at the end of round 1.
2025-04-06 17:00:13,288 (server:359) INFO: ----------- Starting a new training round (Round #2) -------------
2025-04-06 17:00:14,169 (client:354) INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.018625, 'train_total': 2265, 'train_acc': 0.646799, 'train_loss': 2307.186165}}
2025-04-06 17:00:14,364 (client:354) INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.494973, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 274.710279}}
2025-04-06 17:00:15,119 (client:354) INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.131786, 'train_total': 2560, 'train_acc': 0.558984, 'train_loss': 2897.373077}}
2025-04-06 17:00:17,104 (client:354) INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.762702, 'train_total': 6420, 'train_acc': 0.6, 'train_loss': 4896.547544}}
2025-04-06 17:00:17,555 (client:354) INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.006501, 'train_total': 1360, 'train_acc': 0.629412, 'train_loss': 1368.841804}}
2025-04-06 17:00:17,758 (client:354) INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.069954, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 658.021724}}
2025-04-06 17:00:18,223 (client:354) INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.169722, 'train_total': 1435, 'train_acc': 0.569338, 'train_loss': 1678.550475}}
2025-04-06 17:00:18,371 (client:354) INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.487844, 'train_total': 420, 'train_acc': 0.52381, 'train_loss': 624.894651}}
2025-04-06 17:00:18,527 (client:354) INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.734331, 'train_total': 390, 'train_acc': 0.451282, 'train_loss': 676.388933}}
2025-04-06 17:00:19,784 (client:354) INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.030686, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 3983.600767}}
2025-04-06 17:00:19,787 (server:615) INFO: {'Role': 'Server #', 'Round': 1, 'Results_weighted_avg': {'test_avg_loss': 1.829036, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 145.216829, 'val_avg_loss': 1.824711, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 145.106326}, 'Results_avg': {'test_avg_loss': 1.982881, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 91.451784, 'val_avg_loss': 1.998949, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 90.505684}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.651657, 'test_avg_loss_bottom_decile': 1.254803, 'test_avg_loss_top_decile': 2.9399, 'test_avg_loss_min': 0.967633, 'test_avg_loss_max': 2.9399, 'test_avg_loss_bottom10%': 0.967633, 'test_avg_loss_top10%': 2.9399, 'test_avg_loss_cos1': 0.950012, 'test_avg_loss_entropy': 2.246569, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 66.708055, 'test_loss_bottom_decile': 18.775383, 'test_loss_top_decile': 199.513634, 'test_loss_min': 12.579229, 'test_loss_max': 199.513634, 'test_loss_bottom10%': 12.579229, 'test_loss_top10%': 199.513634, 'test_loss_cos1': 0.807905, 'test_loss_entropy': 2.012497, 'val_avg_loss_std': 0.639541, 'val_avg_loss_bottom_decile': 1.272839, 'val_avg_loss_top_decile': 2.878656, 'val_avg_loss_min': 0.963548, 'val_avg_loss_max': 2.878656, 'val_avg_loss_bottom10%': 0.963548, 'val_avg_loss_top10%': 2.878656, 'val_avg_loss_cos1': 0.952441, 'val_avg_loss_entropy': 2.249148, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 66.649774, 'val_loss_bottom_decile': 23.584883, 'val_loss_top_decile': 203.654213, 'val_loss_min': 13.489666, 'val_loss_max': 203.654213, 'val_loss_bottom10%': 13.489666, 'val_loss_top10%': 203.654213, 'val_loss_cos1': 0.80522, 'val_loss_entropy': 2.013576}}
2025-04-06 17:00:19,792 (server:353) INFO: Server: Starting evaluation at the end of round 2.
2025-04-06 17:00:19,792 (server:359) INFO: ----------- Starting a new training round (Round #3) -------------
2025-04-06 17:00:22,051 (client:354) INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.75178, 'train_total': 6420, 'train_acc': 0.603115, 'train_loss': 4826.42812}}
2025-04-06 17:00:23,293 (client:354) INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.021272, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 3947.218107}}
2025-04-06 17:00:23,445 (client:354) INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.69708, 'train_total': 390, 'train_acc': 0.497436, 'train_loss': 661.861008}}
2025-04-06 17:00:23,903 (client:354) INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.155246, 'train_total': 1435, 'train_acc': 0.572125, 'train_loss': 1657.778059}}
2025-04-06 17:00:24,105 (client:354) INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.439897, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 244.143066}}
2025-04-06 17:00:24,545 (client:354) INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.953768, 'train_total': 1360, 'train_acc': 0.645588, 'train_loss': 1297.125145}}
2025-04-06 17:00:25,337 (client:354) INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.106187, 'train_total': 2560, 'train_acc': 0.564844, 'train_loss': 2831.83935}}
2025-04-06 17:00:25,485 (client:354) INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.452593, 'train_total': 420, 'train_acc': 0.533333, 'train_loss': 610.089267}}
2025-04-06 17:00:26,187 (client:354) INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.001217, 'train_total': 2265, 'train_acc': 0.650331, 'train_loss': 2267.756951}}
2025-04-06 17:00:26,377 (client:354) INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.059431, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 651.549853}}
2025-04-06 17:00:26,379 (server:615) INFO: {'Role': 'Server #', 'Round': 2, 'Results_weighted_avg': {'test_avg_loss': 1.833815, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 145.055787, 'val_avg_loss': 1.829075, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 144.872882}, 'Results_avg': {'test_avg_loss': 1.988424, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 91.690743, 'val_avg_loss': 2.004986, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 90.722116}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.690839, 'test_avg_loss_bottom_decile': 1.244177, 'test_avg_loss_top_decile': 3.018069, 'test_avg_loss_min': 0.90607, 'test_avg_loss_max': 3.018069, 'test_avg_loss_bottom10%': 0.90607, 'test_avg_loss_top10%': 3.018069, 'test_avg_loss_cos1': 0.944613, 'test_avg_loss_entropy': 2.239837, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 66.966661, 'test_loss_bottom_decile': 18.220908, 'test_loss_top_decile': 197.82418, 'test_loss_min': 11.778904, 'test_loss_max': 197.82418, 'test_loss_bottom10%': 11.778904, 'test_loss_top10%': 197.82418, 'test_loss_cos1': 0.807551, 'test_loss_entropy': 2.010185, 'val_avg_loss_std': 0.675939, 'val_avg_loss_bottom_decile': 1.262665, 'val_avg_loss_top_decile': 2.950656, 'val_avg_loss_min': 0.902475, 'val_avg_loss_max': 2.950656, 'val_avg_loss_bottom10%': 0.902475, 'val_avg_loss_top10%': 2.950656, 'val_avg_loss_cos1': 0.947599, 'val_avg_loss_entropy': 2.243083, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 66.857627, 'val_loss_bottom_decile': 23.154415, 'val_loss_top_decile': 202.026375, 'val_loss_min': 12.634657, 'val_loss_max': 202.026375, 'val_loss_bottom10%': 12.634657, 'val_loss_top10%': 202.026375, 'val_loss_cos1': 0.805015, 'val_loss_entropy': 2.011649}}
2025-04-06 17:00:26,383 (server:353) INFO: Server: Starting evaluation at the end of round 3.
2025-04-06 17:00:26,384 (server:359) INFO: ----------- Starting a new training round (Round #4) -------------
2025-04-06 17:00:27,012 (client:354) INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.132129, 'train_total': 1435, 'train_acc': 0.571429, 'train_loss': 1624.604453}}
2025-04-06 17:00:27,202 (client:354) INFO: {'Role': 'Client #9', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.048322, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 644.717863}}
2025-04-06 17:00:27,955 (client:354) INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.084831, 'train_total': 2560, 'train_acc': 0.56875, 'train_loss': 2777.167965}}
2025-04-06 17:00:28,381 (client:354) INFO: {'Role': 'Client #4', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.908778, 'train_total': 1360, 'train_acc': 0.658824, 'train_loss': 1235.938097}}
2025-04-06 17:00:29,079 (client:354) INFO: {'Role': 'Client #3', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.978692, 'train_total': 2265, 'train_acc': 0.656071, 'train_loss': 2216.736551}}
2025-04-06 17:00:29,218 (client:354) INFO: {'Role': 'Client #10', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.440697, 'train_total': 420, 'train_acc': 0.583333, 'train_loss': 605.0926}}
2025-04-06 17:00:29,351 (client:354) INFO: {'Role': 'Client #6', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.645986, 'train_total': 390, 'train_acc': 0.520513, 'train_loss': 641.93447}}
2025-04-06 17:00:30,503 (client:354) INFO: {'Role': 'Client #5', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.004211, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 3881.273782}}
2025-04-06 17:00:30,668 (client:354) INFO: {'Role': 'Client #7', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.407166, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 225.97693}}
2025-04-06 17:00:32,455 (client:354) INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.747551, 'train_total': 6420, 'train_acc': 0.602648, 'train_loss': 4799.278916}}
2025-04-06 17:00:32,457 (server:615) INFO: {'Role': 'Server #', 'Round': 3, 'Results_weighted_avg': {'test_avg_loss': 1.833926, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 144.16844, 'val_avg_loss': 1.828721, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 143.87307}, 'Results_avg': {'test_avg_loss': 1.995045, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 91.69628, 'val_avg_loss': 2.011937, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 90.704545}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.719262, 'test_avg_loss_bottom_decile': 1.215952, 'test_avg_loss_top_decile': 3.082613, 'test_avg_loss_min': 0.878688, 'test_avg_loss_max': 3.082613, 'test_avg_loss_bottom10%': 0.878688, 'test_avg_loss_top10%': 3.082613, 'test_avg_loss_cos1': 0.94073, 'test_avg_loss_entropy': 2.23506, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 66.781551, 'test_loss_bottom_decile': 18.004873, 'test_loss_top_decile': 193.336342, 'test_loss_min': 11.422948, 'test_loss_max': 193.336342, 'test_loss_bottom10%': 11.422948, 'test_loss_top10%': 193.336342, 'test_loss_cos1': 0.808344, 'test_loss_entropy': 2.010412, 'val_avg_loss_std': 0.702989, 'val_avg_loss_bottom_decile': 1.234053, 'val_avg_loss_top_decile': 3.006172, 'val_avg_loss_min': 0.874512, 'val_avg_loss_max': 3.006172, 'val_avg_loss_bottom10%': 0.874512, 'val_avg_loss_top10%': 3.006172, 'val_avg_loss_cos1': 0.944032, 'val_avg_loss_entropy': 2.238659, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 66.591746, 'val_loss_bottom_decile': 23.058392, 'val_loss_top_decile': 197.448475, 'val_loss_min': 12.243171, 'val_loss_max': 197.448475, 'val_loss_bottom10%': 12.243171, 'val_loss_top10%': 197.448475, 'val_loss_cos1': 0.806087, 'val_loss_entropy': 2.012302}}
2025-04-06 17:00:32,462 (server:353) INFO: Server: Starting evaluation at the end of round 4.
2025-04-06 17:00:32,463 (server:359) INFO: ----------- Starting a new training round (Round #5) -------------
2025-04-06 17:00:33,330 (client:354) INFO: {'Role': 'Client #3', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.94799, 'train_total': 2265, 'train_acc': 0.660927, 'train_loss': 2147.198082}}
2025-04-06 17:00:33,509 (client:354) INFO: {'Role': 'Client #7', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.39066, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 216.816355}}
2025-04-06 17:00:34,688 (client:354) INFO: {'Role': 'Client #5', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.990183, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 3827.056562}}
2025-04-06 17:00:34,844 (client:354) INFO: {'Role': 'Client #6', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.541082, 'train_total': 390, 'train_acc': 0.54359, 'train_loss': 601.021846}}
2025-04-06 17:00:35,292 (client:354) INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.115144, 'train_total': 1435, 'train_acc': 0.578397, 'train_loss': 1600.231839}}
2025-04-06 17:00:35,441 (client:354) INFO: {'Role': 'Client #10', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.422566, 'train_total': 420, 'train_acc': 0.609524, 'train_loss': 597.477654}}
2025-04-06 17:00:35,647 (client:354) INFO: {'Role': 'Client #9', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.043635, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 641.835309}}
2025-04-06 17:00:36,125 (client:354) INFO: {'Role': 'Client #4', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.865619, 'train_total': 1360, 'train_acc': 0.660294, 'train_loss': 1177.242301}}
2025-04-06 17:00:38,134 (client:354) INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.738609, 'train_total': 6420, 'train_acc': 0.595171, 'train_loss': 4741.872134}}
2025-04-06 17:00:38,899 (client:354) INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.060096, 'train_total': 2560, 'train_acc': 0.572656, 'train_loss': 2713.845755}}
2025-04-06 17:00:38,901 (server:615) INFO: {'Role': 'Server #', 'Round': 4, 'Results_weighted_avg': {'test_avg_loss': 1.816821, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 143.760189, 'val_avg_loss': 1.812169, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 143.533084}, 'Results_avg': {'test_avg_loss': 1.970819, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 90.841063, 'val_avg_loss': 1.986397, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 89.883567}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.692499, 'test_avg_loss_bottom_decile': 1.233239, 'test_avg_loss_top_decile': 3.036504, 'test_avg_loss_min': 0.898181, 'test_avg_loss_max': 3.036504, 'test_avg_loss_bottom10%': 0.898181, 'test_avg_loss_top10%': 3.036504, 'test_avg_loss_cos1': 0.943453, 'test_avg_loss_entropy': 2.238731, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 66.433509, 'test_loss_bottom_decile': 18.011859, 'test_loss_top_decile': 196.085037, 'test_loss_min': 11.676352, 'test_loss_max': 196.085037, 'test_loss_bottom10%': 11.676352, 'test_loss_top10%': 196.085037, 'test_loss_cos1': 0.807181, 'test_loss_entropy': 2.009632, 'val_avg_loss_std': 0.675338, 'val_avg_loss_bottom_decile': 1.251895, 'val_avg_loss_top_decile': 2.946648, 'val_avg_loss_min': 0.889752, 'val_avg_loss_max': 2.946648, 'val_avg_loss_bottom10%': 0.889752, 'val_avg_loss_top10%': 2.946648, 'val_avg_loss_cos1': 0.946778, 'val_avg_loss_entropy': 2.242232, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 66.319047, 'val_loss_bottom_decile': 23.0123, 'val_loss_top_decile': 200.303234, 'val_loss_min': 12.456533, 'val_loss_max': 200.303234, 'val_loss_bottom10%': 12.456533, 'val_loss_top10%': 200.303234, 'val_loss_cos1': 0.804675, 'val_loss_entropy': 2.011068}}
2025-04-06 17:00:38,906 (server:353) INFO: Server: Starting evaluation at the end of round 5.
2025-04-06 17:00:38,907 (server:359) INFO: ----------- Starting a new training round (Round #6) -------------
2025-04-06 17:00:39,278 (client:354) INFO: {'Role': 'Client #10', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.417836, 'train_total': 420, 'train_acc': 0.604762, 'train_loss': 595.491323}}
2025-04-06 17:00:39,694 (client:354) INFO: {'Role': 'Client #4', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.848399, 'train_total': 1360, 'train_acc': 0.666912, 'train_loss': 1153.822281}}
2025-04-06 17:00:39,884 (client:354) INFO: {'Role': 'Client #9', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.036359, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 637.360606}}
2025-04-06 17:00:40,650 (client:354) INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.048971, 'train_total': 2560, 'train_acc': 0.577734, 'train_loss': 2685.365089}}
2025-04-06 17:00:41,092 (client:354) INFO: {'Role': 'Client #1', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.109892, 'train_total': 1435, 'train_acc': 0.581882, 'train_loss': 1592.695651}}
2025-04-06 17:00:41,833 (client:354) INFO: {'Role': 'Client #3', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.942159, 'train_total': 2265, 'train_acc': 0.662252, 'train_loss': 2133.989675}}
2025-04-06 17:00:42,032 (client:354) INFO: {'Role': 'Client #7', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.362565, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 201.223395}}
2025-04-06 17:00:43,996 (client:354) INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.727071, 'train_total': 6420, 'train_acc': 0.605919, 'train_loss': 4667.796687}}
2025-04-06 17:00:44,154 (client:354) INFO: {'Role': 'Client #6', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.491103, 'train_total': 390, 'train_acc': 0.538462, 'train_loss': 581.530071}}
2025-04-06 17:00:45,459 (client:354) INFO: {'Role': 'Client #5', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.985074, 'train_total': 3865, 'train_acc': 0.592497, 'train_loss': 3807.309333}}
2025-04-06 17:00:45,461 (server:615) INFO: {'Role': 'Server #', 'Round': 5, 'Results_weighted_avg': {'test_avg_loss': 1.822885, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 141.940678, 'val_avg_loss': 1.819056, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 141.721587}, 'Results_avg': {'test_avg_loss': 1.995784, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 91.144275, 'val_avg_loss': 2.01264, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 90.225178}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.753018, 'test_avg_loss_bottom_decile': 1.175806, 'test_avg_loss_top_decile': 3.135414, 'test_avg_loss_min': 0.839838, 'test_avg_loss_max': 3.135414, 'test_avg_loss_bottom10%': 0.839838, 'test_avg_loss_top10%': 3.135414, 'test_avg_loss_cos1': 0.935618, 'test_avg_loss_entropy': 2.22848, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 65.95764, 'test_loss_bottom_decile': 17.642638, 'test_loss_top_decile': 186.953122, 'test_loss_min': 10.917891, 'test_loss_max': 186.953122, 'test_loss_bottom10%': 10.917891, 'test_loss_top10%': 186.953122, 'test_loss_cos1': 0.810125, 'test_loss_entropy': 2.012132, 'val_avg_loss_std': 0.736463, 'val_avg_loss_bottom_decile': 1.19627, 'val_avg_loss_top_decile': 3.025922, 'val_avg_loss_min': 0.827446, 'val_avg_loss_max': 3.025922, 'val_avg_loss_bottom10%': 0.827446, 'val_avg_loss_top10%': 3.025922, 'val_avg_loss_cos1': 0.939103, 'val_avg_loss_entropy': 2.23214, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 65.894614, 'val_loss_bottom_decile': 22.810982, 'val_loss_top_decile': 191.403191, 'val_loss_min': 11.584243, 'val_loss_max': 191.403191, 'val_loss_bottom10%': 11.584243, 'val_loss_top10%': 191.403191, 'val_loss_cos1': 0.807558, 'val_loss_entropy': 2.013354}}
2025-04-06 17:00:45,467 (server:353) INFO: Server: Starting evaluation at the end of round 6.
2025-04-06 17:00:45,467 (server:359) INFO: ----------- Starting a new training round (Round #7) -------------
2025-04-06 17:00:46,975 (client:354) INFO: {'Role': 'Client #5', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.957032, 'train_total': 3865, 'train_acc': 0.596895, 'train_loss': 3698.92933}}
2025-04-06 17:00:49,078 (client:354) INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.723987, 'train_total': 6420, 'train_acc': 0.61028, 'train_loss': 4647.993753}}
2025-04-06 17:00:49,889 (client:354) INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.030797, 'train_total': 2560, 'train_acc': 0.58125, 'train_loss': 2638.840292}}
2025-04-06 17:00:50,098 (client:354) INFO: {'Role': 'Client #9', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.037254, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 637.911366}}
2025-04-06 17:00:50,252 (client:354) INFO: {'Role': 'Client #10', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.418706, 'train_total': 420, 'train_acc': 0.62619, 'train_loss': 595.856578}}
2025-04-06 17:00:51,032 (client:354) INFO: {'Role': 'Client #3', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.912147, 'train_total': 2265, 'train_acc': 0.667108, 'train_loss': 2066.011855}}
2025-04-06 17:00:51,459 (client:354) INFO: {'Role': 'Client #4', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.817883, 'train_total': 1360, 'train_acc': 0.672794, 'train_loss': 1112.321253}}
2025-04-06 17:00:51,933 (client:354) INFO: {'Role': 'Client #1', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.09866, 'train_total': 1435, 'train_acc': 0.578397, 'train_loss': 1576.57748}}
2025-04-06 17:00:52,089 (client:354) INFO: {'Role': 'Client #6', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.378783, 'train_total': 390, 'train_acc': 0.553846, 'train_loss': 537.725481}}
2025-04-06 17:00:52,285 (client:354) INFO: {'Role': 'Client #7', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.351284, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 194.962631}}
2025-04-06 17:00:52,288 (server:615) INFO: {'Role': 'Server #', 'Round': 6, 'Results_weighted_avg': {'test_avg_loss': 1.786132, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 140.731221, 'val_avg_loss': 1.785819, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 140.896238}, 'Results_avg': {'test_avg_loss': 1.947118, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 89.306591, 'val_avg_loss': 1.96334, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 88.576612}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.693528, 'test_avg_loss_bottom_decile': 1.204487, 'test_avg_loss_top_decile': 3.016281, 'test_avg_loss_min': 0.885916, 'test_avg_loss_max': 3.016281, 'test_avg_loss_bottom10%': 0.885916, 'test_avg_loss_top10%': 3.016281, 'test_avg_loss_cos1': 0.942028, 'test_avg_loss_entropy': 2.23695, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 64.871224, 'test_loss_bottom_decile': 17.646208, 'test_loss_top_decile': 191.513454, 'test_loss_min': 11.51691, 'test_loss_max': 191.513454, 'test_loss_bottom10%': 11.51691, 'test_loss_top10%': 191.513454, 'test_loss_cos1': 0.809076, 'test_loss_entropy': 2.012574, 'val_avg_loss_std': 0.677156, 'val_avg_loss_bottom_decile': 1.228925, 'val_avg_loss_top_decile': 2.875054, 'val_avg_loss_min': 0.858345, 'val_avg_loss_max': 2.875054, 'val_avg_loss_bottom10%': 0.858345, 'val_avg_loss_top10%': 2.875054, 'val_avg_loss_cos1': 0.945352, 'val_avg_loss_entropy': 2.240103, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 65.091314, 'val_loss_bottom_decile': 22.800974, 'val_loss_top_decile': 196.628021, 'val_loss_min': 12.01683, 'val_loss_max': 196.628021, 'val_loss_bottom10%': 12.01683, 'val_loss_top10%': 196.628021, 'val_loss_cos1': 0.805818, 'val_loss_entropy': 2.012477}}
2025-04-06 17:00:52,292 (server:353) INFO: Server: Starting evaluation at the end of round 7.
2025-04-06 17:00:52,293 (server:359) INFO: ----------- Starting a new training round (Round #8) -------------
2025-04-06 17:00:52,643 (client:354) INFO: {'Role': 'Client #10', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.409911, 'train_total': 420, 'train_acc': 0.62381, 'train_loss': 592.162711}}
2025-04-06 17:00:54,972 (client:354) INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.719455, 'train_total': 6420, 'train_acc': 0.614798, 'train_loss': 4618.901722}}
2025-04-06 17:00:55,204 (client:354) INFO: {'Role': 'Client #7', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.325315, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 180.549695}}
2025-04-06 17:00:55,990 (client:354) INFO: {'Role': 'Client #3', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.89501, 'train_total': 2265, 'train_acc': 0.672848, 'train_loss': 2027.19854}}
2025-04-06 17:00:57,050 (client:354) INFO: {'Role': 'Client #5', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.909208, 'train_total': 3865, 'train_acc': 0.623286, 'train_loss': 3514.089539}}
2025-04-06 17:00:57,426 (client:354) INFO: {'Role': 'Client #4', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.812606, 'train_total': 1360, 'train_acc': 0.675, 'train_loss': 1105.143947}}
2025-04-06 17:00:57,611 (client:354) INFO: {'Role': 'Client #9', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.051862, 'train_total': 615, 'train_acc': 0.739837, 'train_loss': 646.895206}}
2025-04-06 17:00:58,005 (client:354) INFO: {'Role': 'Client #1', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.077535, 'train_total': 1435, 'train_acc': 0.573519, 'train_loss': 1546.262988}}
2025-04-06 17:00:58,667 (client:354) INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.017262, 'train_total': 2560, 'train_acc': 0.580469, 'train_loss': 2604.190273}}
2025-04-06 17:00:58,799 (client:354) INFO: {'Role': 'Client #6', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.335144, 'train_total': 390, 'train_acc': 0.558974, 'train_loss': 520.706106}}
2025-04-06 17:00:58,802 (server:615) INFO: {'Role': 'Server #', 'Round': 7, 'Results_weighted_avg': {'test_avg_loss': 1.786916, 'test_total': 50.0, 'test_acc': 0.294, 'test_loss': 137.892465, 'val_avg_loss': 1.790836, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 138.360905}, 'Results_avg': {'test_avg_loss': 1.976816, 'test_total': 50.0, 'test_acc': 0.297786, 'test_loss': 89.345797, 'val_avg_loss': 1.99412, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 88.82545}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.764102, 'test_avg_loss_bottom_decile': 1.126193, 'test_avg_loss_top_decile': 3.164674, 'test_avg_loss_min': 0.827306, 'test_avg_loss_max': 3.164674, 'test_avg_loss_bottom10%': 0.827306, 'test_avg_loss_top10%': 3.164674, 'test_avg_loss_cos1': 0.932745, 'test_avg_loss_entropy': 2.224852, 'test_acc_std': 0.356622, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.640947, 'test_acc_entropy': 1.494713, 'test_loss_std': 63.827402, 'test_loss_bottom_decile': 17.226898, 'test_loss_top_decile': 179.064754, 'test_loss_min': 10.754981, 'test_loss_max': 179.064754, 'test_loss_bottom10%': 10.754981, 'test_loss_top10%': 179.064754, 'test_loss_cos1': 0.813695, 'test_loss_entropy': 2.017857, 'val_avg_loss_std': 0.74611, 'val_avg_loss_bottom_decile': 1.156186, 'val_avg_loss_top_decile': 2.941709, 'val_avg_loss_min': 0.784454, 'val_avg_loss_max': 2.941709, 'val_avg_loss_bottom10%': 0.784454, 'val_avg_loss_top10%': 2.941709, 'val_avg_loss_cos1': 0.936589, 'val_avg_loss_entropy': 2.228272, 'val_acc_std': 0.346005, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.635581, 'val_acc_entropy': 1.483057, 'val_loss_std': 64.370404, 'val_loss_bottom_decile': 22.843212, 'val_loss_top_decile': 184.989826, 'val_loss_min': 10.982349, 'val_loss_max': 184.989826, 'val_loss_bottom10%': 10.982349, 'val_loss_top10%': 184.989826, 'val_loss_cos1': 0.809732, 'val_loss_entropy': 2.016184}}
2025-04-06 17:00:58,807 (server:353) INFO: Server: Starting evaluation at the end of round 8.
2025-04-06 17:00:58,808 (server:359) INFO: ----------- Starting a new training round (Round #9) -------------
2025-04-06 17:00:59,743 (client:354) INFO: {'Role': 'Client #2', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.01308, 'train_total': 2560, 'train_acc': 0.576172, 'train_loss': 2593.484222}}
2025-04-06 17:01:00,858 (client:354) INFO: {'Role': 'Client #5', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.894816, 'train_total': 3865, 'train_acc': 0.63053, 'train_loss': 3458.463256}}
2025-04-06 17:01:01,224 (client:354) INFO: {'Role': 'Client #1', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.083851, 'train_total': 1435, 'train_acc': 0.574913, 'train_loss': 1555.325714}}
2025-04-06 17:01:02,864 (client:354) INFO: {'Role': 'Client #8', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.715226, 'train_total': 6420, 'train_acc': 0.6081, 'train_loss': 4591.751745}}
2025-04-06 17:01:03,225 (client:354) INFO: {'Role': 'Client #4', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.802043, 'train_total': 1360, 'train_acc': 0.672059, 'train_loss': 1090.778419}}
2025-04-06 17:01:03,405 (client:354) INFO: {'Role': 'Client #7', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.311768, 'train_total': 555, 'train_acc': 0.951351, 'train_loss': 173.031145}}
2025-04-06 17:01:04,120 (client:354) INFO: {'Role': 'Client #3', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.87743, 'train_total': 2265, 'train_acc': 0.671965, 'train_loss': 1987.379081}}
2025-04-06 17:01:04,260 (client:354) INFO: {'Role': 'Client #6', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.240087, 'train_total': 390, 'train_acc': 0.569231, 'train_loss': 483.633925}}
2025-04-06 17:01:04,401 (client:354) INFO: {'Role': 'Client #10', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.424085, 'train_total': 420, 'train_acc': 0.57619, 'train_loss': 598.115494}}
2025-04-06 17:01:04,591 (client:354) INFO: {'Role': 'Client #9', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.012869, 'train_total': 615, 'train_acc': 0.738211, 'train_loss': 622.914631}}
2025-04-06 17:01:04,594 (server:615) INFO: {'Role': 'Server #', 'Round': 8, 'Results_weighted_avg': {'test_avg_loss': 1.80994, 'test_total': 50.0, 'test_acc': 0.29, 'test_loss': 139.014837, 'val_avg_loss': 1.82524, 'val_total': 49.6, 'val_acc': 0.290323, 'val_loss': 140.875639}, 'Results_avg': {'test_avg_loss': 2.019682, 'test_total': 50.0, 'test_acc': 0.288008, 'test_loss': 90.497001, 'val_avg_loss': 2.032969, 'val_total': 49.6, 'val_acc': 0.276446, 'val_loss': 90.531884}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.820057, 'test_avg_loss_bottom_decile': 1.156689, 'test_avg_loss_top_decile': 3.299264, 'test_avg_loss_min': 0.746231, 'test_avg_loss_max': 3.299264, 'test_avg_loss_bottom10%': 0.746231, 'test_avg_loss_top10%': 3.299264, 'test_avg_loss_cos1': 0.926537, 'test_avg_loss_entropy': 2.215396, 'test_acc_std': 0.320993, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.923077, 'test_acc_min': 0.0, 'test_acc_max': 0.923077, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.923077, 'test_acc_cos1': 0.667829, 'test_acc_entropy': 1.625062, 'test_loss_std': 63.906562, 'test_loss_bottom_decile': 16.712043, 'test_loss_top_decile': 183.913518, 'test_loss_min': 9.701005, 'test_loss_max': 183.913518, 'test_loss_bottom10%': 9.701005, 'test_loss_top10%': 183.913518, 'test_loss_cos1': 0.816856, 'test_loss_entropy': 2.021526, 'val_avg_loss_std': 0.793535, 'val_avg_loss_bottom_decile': 1.205697, 'val_avg_loss_top_decile': 2.947066, 'val_avg_loss_min': 0.669455, 'val_avg_loss_max': 2.947066, 'val_avg_loss_bottom10%': 0.669455, 'val_avg_loss_top10%': 2.947066, 'val_avg_loss_cos1': 0.93155, 'val_avg_loss_entropy': 2.21935, 'val_acc_std': 0.325704, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.0, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.647101, 'val_acc_entropy': 1.60644, 'val_loss_std': 65.740492, 'val_loss_bottom_decile': 22.851234, 'val_loss_top_decile': 192.911526, 'val_loss_min': 9.372364, 'val_loss_max': 192.911526, 'val_loss_bottom10%': 9.372364, 'val_loss_top10%': 192.911526, 'val_loss_cos1': 0.809165, 'val_loss_entropy': 2.013344}}
2025-04-06 17:01:04,599 (server:353) INFO: Server: Starting evaluation at the end of round 9.
2025-04-06 17:01:04,599 (server:359) INFO: ----------- Starting a new training round (Round #10) -------------
2025-04-06 17:01:05,531 (client:354) INFO: {'Role': 'Client #3', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.855744, 'train_total': 2265, 'train_acc': 0.672406, 'train_loss': 1938.260308}}
2025-04-06 17:01:07,355 (client:354) INFO: {'Role': 'Client #8', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.705589, 'train_total': 6420, 'train_acc': 0.612773, 'train_loss': 4529.879688}}
2025-04-06 17:01:07,525 (client:354) INFO: {'Role': 'Client #7', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.305467, 'train_total': 555, 'train_acc': 0.954955, 'train_loss': 169.53413}}
2025-04-06 17:01:07,657 (client:354) INFO: {'Role': 'Client #10', 'Round': 10, 'Results_raw': {'train_avg_loss': 1.438695, 'train_total': 420, 'train_acc': 0.6, 'train_loss': 604.251758}}
2025-04-06 17:01:08,743 (client:354) INFO: {'Role': 'Client #5', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.889388, 'train_total': 3865, 'train_acc': 0.637257, 'train_loss': 3437.486226}}
2025-04-06 17:01:09,172 (client:354) INFO: {'Role': 'Client #1', 'Round': 10, 'Results_raw': {'train_avg_loss': 1.082143, 'train_total': 1435, 'train_acc': 0.569338, 'train_loss': 1552.874841}}
2025-04-06 17:01:09,309 (client:354) INFO: {'Role': 'Client #6', 'Round': 10, 'Results_raw': {'train_avg_loss': 1.197104, 'train_total': 390, 'train_acc': 0.571795, 'train_loss': 466.870728}}
2025-04-06 17:01:10,031 (client:354) INFO: {'Role': 'Client #2', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.998852, 'train_total': 2560, 'train_acc': 0.580859, 'train_loss': 2557.062122}}
2025-04-06 17:01:10,440 (client:354) INFO: {'Role': 'Client #4', 'Round': 10, 'Results_raw': {'train_avg_loss': 0.78423, 'train_total': 1360, 'train_acc': 0.677941, 'train_loss': 1066.552935}}
2025-04-06 17:01:10,672 (client:354) INFO: {'Role': 'Client #9', 'Round': 10, 'Results_raw': {'train_avg_loss': 1.023388, 'train_total': 615, 'train_acc': 0.725203, 'train_loss': 629.383316}}
2025-04-06 17:01:10,675 (server:615) INFO: {'Role': 'Server #', 'Round': 9, 'Results_weighted_avg': {'test_avg_loss': 1.795525, 'test_total': 50.0, 'test_acc': 0.316, 'test_loss': 138.198305, 'val_avg_loss': 1.830196, 'val_total': 49.6, 'val_acc': 0.302419, 'val_loss': 141.851466}, 'Results_avg': {'test_avg_loss': 2.028049, 'test_total': 50.0, 'test_acc': 0.317732, 'test_loss': 89.776262, 'val_avg_loss': 2.051314, 'val_total': 49.6, 'val_acc': 0.285677, 'val_loss': 90.777738}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.794678, 'test_avg_loss_bottom_decile': 1.14704, 'test_avg_loss_top_decile': 3.446589, 'test_avg_loss_min': 0.835249, 'test_avg_loss_max': 3.446589, 'test_avg_loss_bottom10%': 0.835249, 'test_avg_loss_top10%': 3.446589, 'test_avg_loss_cos1': 0.931072, 'test_avg_loss_entropy': 2.223379, 'test_acc_std': 0.290967, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.737486, 'test_acc_entropy': 1.837345, 'test_loss_std': 62.439483, 'test_loss_bottom_decile': 18.153838, 'test_loss_top_decile': 182.379327, 'test_loss_min': 10.858235, 'test_loss_max': 182.379327, 'test_loss_bottom10%': 10.858235, 'test_loss_top10%': 182.379327, 'test_loss_cos1': 0.820963, 'test_loss_entropy': 2.031957, 'val_avg_loss_std': 0.740902, 'val_avg_loss_bottom_decile': 1.216391, 'val_avg_loss_top_decile': 2.934023, 'val_avg_loss_min': 0.758478, 'val_avg_loss_max': 2.934023, 'val_avg_loss_bottom10%': 0.758478, 'val_avg_loss_top10%': 2.934023, 'val_avg_loss_cos1': 0.940532, 'val_avg_loss_entropy': 2.231681, 'val_acc_std': 0.273501, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 0.857143, 'val_acc_min': 0.0, 'val_acc_max': 0.857143, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.857143, 'val_acc_cos1': 0.722333, 'val_acc_entropy': 1.813827, 'val_loss_std': 64.854008, 'val_loss_bottom_decile': 25.481369, 'val_loss_top_decile': 194.622612, 'val_loss_min': 10.618689, 'val_loss_max': 194.622612, 'val_loss_bottom10%': 10.618689, 'val_loss_top10%': 194.622612, 'val_loss_cos1': 0.813679, 'val_loss_entropy': 2.023823}}
2025-04-06 17:01:10,682 (server:353) INFO: Server: Starting evaluation at the end of round 10.
2025-04-06 17:01:10,682 (server:359) INFO: ----------- Starting a new training round (Round #11) -------------
2025-04-06 17:01:11,363 (client:354) INFO: {'Role': 'Client #1', 'Round': 11, 'Results_raw': {'train_avg_loss': 1.058469, 'train_total': 1435, 'train_acc': 0.570732, 'train_loss': 1518.902665}}
2025-04-06 17:01:11,509 (client:354) INFO: {'Role': 'Client #6', 'Round': 11, 'Results_raw': {'train_avg_loss': 1.209055, 'train_total': 390, 'train_acc': 0.564103, 'train_loss': 471.531475}}
2025-04-06 17:01:12,277 (client:354) INFO: {'Role': 'Client #2', 'Round': 11, 'Results_raw': {'train_avg_loss': 1.002379, 'train_total': 2560, 'train_acc': 0.580469, 'train_loss': 2566.089598}}
2025-04-06 17:01:12,459 (client:354) INFO: {'Role': 'Client #7', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.277024, 'train_total': 555, 'train_acc': 0.951351, 'train_loss': 153.748459}}
2025-04-06 17:01:14,595 (client:354) INFO: {'Role': 'Client #8', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.709468, 'train_total': 6420, 'train_acc': 0.61947, 'train_loss': 4554.781657}}
2025-04-06 17:01:14,765 (client:354) INFO: {'Role': 'Client #10', 'Round': 11, 'Results_raw': {'train_avg_loss': 1.515813, 'train_total': 420, 'train_acc': 0.569048, 'train_loss': 636.64162}}
2025-04-06 17:01:15,278 (client:354) INFO: {'Role': 'Client #4', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.80661, 'train_total': 1360, 'train_acc': 0.666176, 'train_loss': 1096.989239}}
2025-04-06 17:01:15,948 (client:354) INFO: {'Role': 'Client #3', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.85521, 'train_total': 2265, 'train_acc': 0.674172, 'train_loss': 1937.049824}}
2025-04-06 17:01:16,126 (client:354) INFO: {'Role': 'Client #9', 'Round': 11, 'Results_raw': {'train_avg_loss': 1.015276, 'train_total': 615, 'train_acc': 0.733333, 'train_loss': 624.394512}}
2025-04-06 17:01:17,224 (client:354) INFO: {'Role': 'Client #5', 'Round': 11, 'Results_raw': {'train_avg_loss': 0.900885, 'train_total': 3865, 'train_acc': 0.628202, 'train_loss': 3481.920101}}
2025-04-06 17:01:17,229 (server:615) INFO: {'Role': 'Server #', 'Round': 10, 'Results_weighted_avg': {'test_avg_loss': 1.94054, 'test_total': 50.0, 'test_acc': 0.31, 'test_loss': 144.032806, 'val_avg_loss': 1.991498, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 148.866243}, 'Results_avg': {'test_avg_loss': 2.231665, 'test_total': 50.0, 'test_acc': 0.314545, 'test_loss': 97.027002, 'val_avg_loss': 2.270337, 'val_total': 49.6, 'val_acc': 0.285586, 'val_loss': 98.778311}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 1.019886, 'test_avg_loss_bottom_decile': 1.124212, 'test_avg_loss_top_decile': 3.823047, 'test_avg_loss_min': 0.633099, 'test_avg_loss_max': 3.823047, 'test_avg_loss_bottom10%': 0.633099, 'test_avg_loss_top10%': 3.823047, 'test_avg_loss_cos1': 0.909521, 'test_avg_loss_entropy': 2.189741, 'test_acc_std': 0.306217, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.923077, 'test_acc_min': 0.0, 'test_acc_max': 0.923077, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.923077, 'test_acc_cos1': 0.716529, 'test_acc_entropy': 1.802009, 'test_loss_std': 66.753731, 'test_loss_bottom_decile': 17.710569, 'test_loss_top_decile': 180.862578, 'test_loss_min': 8.230287, 'test_loss_max': 180.862578, 'test_loss_bottom10%': 8.230287, 'test_loss_top10%': 180.862578, 'test_loss_cos1': 0.823853, 'test_loss_entropy': 2.030046, 'val_avg_loss_std': 0.954065, 'val_avg_loss_bottom_decile': 1.196608, 'val_avg_loss_top_decile': 3.371782, 'val_avg_loss_min': 0.608216, 'val_avg_loss_max': 3.371782, 'val_avg_loss_bottom10%': 0.608216, 'val_avg_loss_top10%': 3.371782, 'val_avg_loss_cos1': 0.921906, 'val_avg_loss_entropy': 2.203554, 'val_acc_std': 0.288494, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 0.928571, 'val_acc_min': 0.0, 'val_acc_max': 0.928571, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.928571, 'val_acc_cos1': 0.703515, 'val_acc_entropy': 1.782307, 'val_loss_std': 70.517826, 'val_loss_bottom_decile': 27.02527, 'val_loss_top_decile': 198.853304, 'val_loss_min': 8.515022, 'val_loss_max': 198.853304, 'val_loss_bottom10%': 8.515022, 'val_loss_top10%': 198.853304, 'val_loss_cos1': 0.813882, 'val_loss_entropy': 2.020185}}
2025-04-06 17:01:17,239 (server:353) INFO: Server: Starting evaluation at the end of round 11.
2025-04-06 17:01:17,240 (server:359) INFO: ----------- Starting a new training round (Round #12) -------------
2025-04-06 17:01:17,692 (client:354) INFO: {'Role': 'Client #9', 'Round': 12, 'Results_raw': {'train_avg_loss': 1.177686, 'train_total': 615, 'train_acc': 0.661789, 'train_loss': 724.276648}}
2025-04-06 17:01:17,823 (client:354) INFO: {'Role': 'Client #10', 'Round': 12, 'Results_raw': {'train_avg_loss': 1.473626, 'train_total': 420, 'train_acc': 0.583333, 'train_loss': 618.922761}}
2025-04-06 17:01:17,959 (client:354) INFO: {'Role': 'Client #6', 'Round': 12, 'Results_raw': {'train_avg_loss': 1.122422, 'train_total': 390, 'train_acc': 0.592308, 'train_loss': 437.744567}}
2025-04-06 17:01:19,803 (client:354) INFO: {'Role': 'Client #8', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.702145, 'train_total': 6420, 'train_acc': 0.626324, 'train_loss': 4507.770484}}
2025-04-06 17:01:19,991 (client:354) INFO: {'Role': 'Client #7', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.301147, 'train_total': 555, 'train_acc': 0.942342, 'train_loss': 167.136645}}
2025-04-06 17:01:21,130 (client:354) INFO: {'Role': 'Client #5', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.917616, 'train_total': 3865, 'train_acc': 0.612937, 'train_loss': 3546.584414}}
2025-04-06 17:01:21,798 (client:354) INFO: {'Role': 'Client #3', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.821654, 'train_total': 2265, 'train_acc': 0.67947, 'train_loss': 1861.045185}}
2025-04-06 17:01:22,520 (client:354) INFO: {'Role': 'Client #2', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.978204, 'train_total': 2560, 'train_acc': 0.584375, 'train_loss': 2504.203291}}
2025-04-06 17:01:22,918 (client:354) INFO: {'Role': 'Client #4', 'Round': 12, 'Results_raw': {'train_avg_loss': 0.747702, 'train_total': 1360, 'train_acc': 0.683088, 'train_loss': 1016.874251}}
2025-04-06 17:01:23,324 (client:354) INFO: {'Role': 'Client #1', 'Round': 12, 'Results_raw': {'train_avg_loss': 1.093672, 'train_total': 1435, 'train_acc': 0.568641, 'train_loss': 1569.419731}}
2025-04-06 17:01:23,327 (server:615) INFO: {'Role': 'Server #', 'Round': 11, 'Results_weighted_avg': {'test_avg_loss': 1.87629, 'test_total': 50.0, 'test_acc': 0.3, 'test_loss': 144.626722, 'val_avg_loss': 1.915731, 'val_total': 49.6, 'val_acc': 0.280242, 'val_loss': 149.554626}, 'Results_avg': {'test_avg_loss': 2.14317, 'test_total': 50.0, 'test_acc': 0.302098, 'test_loss': 93.814513, 'val_avg_loss': 2.150357, 'val_total': 49.6, 'val_acc': 0.272075, 'val_loss': 95.020237}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.885874, 'test_avg_loss_bottom_decile': 1.240087, 'test_avg_loss_top_decile': 3.831258, 'test_avg_loss_min': 0.76839, 'test_avg_loss_max': 3.831258, 'test_avg_loss_bottom10%': 0.76839, 'test_avg_loss_top10%': 3.831258, 'test_avg_loss_cos1': 0.924162, 'test_avg_loss_entropy': 2.214218, 'test_acc_std': 0.271382, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.743913, 'test_acc_entropy': 1.86242, 'test_loss_std': 64.760508, 'test_loss_bottom_decile': 19.269603, 'test_loss_top_decile': 197.173856, 'test_loss_min': 9.989065, 'test_loss_max': 197.173856, 'test_loss_bottom10%': 9.989065, 'test_loss_top10%': 197.173856, 'test_loss_cos1': 0.822963, 'test_loss_entropy': 2.035842, 'val_avg_loss_std': 0.82794, 'val_avg_loss_bottom_decile': 1.343268, 'val_avg_loss_top_decile': 3.210408, 'val_avg_loss_min': 0.715877, 'val_avg_loss_max': 3.210408, 'val_avg_loss_bottom10%': 0.715877, 'val_avg_loss_top10%': 3.210408, 'val_avg_loss_cos1': 0.933218, 'val_avg_loss_entropy': 2.221647, 'val_acc_std': 0.270965, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 0.857143, 'val_acc_min': 0.0, 'val_acc_max': 0.857143, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.857143, 'val_acc_cos1': 0.708551, 'val_acc_entropy': 1.753969, 'val_loss_std': 68.496183, 'val_loss_bottom_decile': 24.070686, 'val_loss_top_decile': 214.92284, 'val_loss_min': 10.022277, 'val_loss_max': 214.92284, 'val_loss_bottom10%': 10.022277, 'val_loss_top10%': 214.92284, 'val_loss_cos1': 0.811204, 'val_loss_entropy': 2.019805}}
2025-04-06 17:01:23,331 (server:353) INFO: Server: Starting evaluation at the end of round 12.
2025-04-06 17:01:23,331 (server:359) INFO: ----------- Starting a new training round (Round #13) -------------
2025-04-06 17:01:23,960 (client:354) INFO: {'Role': 'Client #4', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.829086, 'train_total': 1360, 'train_acc': 0.655882, 'train_loss': 1127.557275}}
2025-04-06 17:01:24,375 (client:354) INFO: {'Role': 'Client #1', 'Round': 13, 'Results_raw': {'train_avg_loss': 1.056677, 'train_total': 1435, 'train_acc': 0.574913, 'train_loss': 1516.330792}}
2025-04-06 17:01:24,508 (client:354) INFO: {'Role': 'Client #6', 'Round': 13, 'Results_raw': {'train_avg_loss': 1.30237, 'train_total': 390, 'train_acc': 0.558974, 'train_loss': 507.924289}}
2025-04-06 17:01:24,687 (client:354) INFO: {'Role': 'Client #7', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.282298, 'train_total': 555, 'train_acc': 0.94955, 'train_loss': 156.675314}}
2025-04-06 17:01:26,543 (client:354) INFO: {'Role': 'Client #8', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.697905, 'train_total': 6420, 'train_acc': 0.629128, 'train_loss': 4480.549759}}
2025-04-06 17:01:26,680 (client:354) INFO: {'Role': 'Client #10', 'Round': 13, 'Results_raw': {'train_avg_loss': 1.564248, 'train_total': 420, 'train_acc': 0.580952, 'train_loss': 656.984116}}
2025-04-06 17:01:27,345 (client:354) INFO: {'Role': 'Client #3', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.856005, 'train_total': 2265, 'train_acc': 0.671523, 'train_loss': 1938.850484}}
2025-04-06 17:01:28,529 (client:354) INFO: {'Role': 'Client #5', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.896063, 'train_total': 3865, 'train_acc': 0.6326, 'train_loss': 3463.283818}}
2025-04-06 17:01:29,244 (client:354) INFO: {'Role': 'Client #2', 'Round': 13, 'Results_raw': {'train_avg_loss': 0.986009, 'train_total': 2560, 'train_acc': 0.578125, 'train_loss': 2524.183052}}
2025-04-06 17:01:29,428 (client:354) INFO: {'Role': 'Client #9', 'Round': 13, 'Results_raw': {'train_avg_loss': 1.052313, 'train_total': 615, 'train_acc': 0.712195, 'train_loss': 647.172377}}
2025-04-06 17:01:29,430 (server:615) INFO: {'Role': 'Server #', 'Round': 12, 'Results_weighted_avg': {'test_avg_loss': 2.174052, 'test_total': 50.0, 'test_acc': 0.314, 'test_loss': 153.564419, 'val_avg_loss': 2.178654, 'val_total': 49.6, 'val_acc': 0.3125, 'val_loss': 152.5352}, 'Results_avg': {'test_avg_loss': 2.506239, 'test_total': 50.0, 'test_acc': 0.312749, 'test_loss': 108.702598, 'val_avg_loss': 2.576844, 'val_total': 49.6, 'val_acc': 0.307859, 'val_loss': 108.06122}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 1.332813, 'test_avg_loss_bottom_decile': 0.966967, 'test_avg_loss_top_decile': 4.428354, 'test_avg_loss_min': 0.474685, 'test_avg_loss_max': 4.428354, 'test_avg_loss_bottom10%': 0.474685, 'test_avg_loss_top10%': 4.428354, 'test_avg_loss_cos1': 0.882915, 'test_avg_loss_entropy': 2.146567, 'test_acc_std': 0.347414, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 1.0, 'test_acc_min': 0.0, 'test_acc_max': 1.0, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 1.0, 'test_acc_cos1': 0.669055, 'test_acc_entropy': 1.636479, 'test_loss_std': 79.647925, 'test_loss_bottom_decile': 17.932468, 'test_loss_top_decile': 236.745137, 'test_loss_min': 6.170902, 'test_loss_max': 236.745137, 'test_loss_bottom10%': 6.170902, 'test_loss_top10%': 236.745137, 'test_loss_cos1': 0.806643, 'test_loss_entropy': 1.999901, 'val_avg_loss_std': 1.286778, 'val_avg_loss_bottom_decile': 1.023135, 'val_avg_loss_top_decile': 4.156424, 'val_avg_loss_min': 0.629325, 'val_avg_loss_max': 4.156424, 'val_avg_loss_bottom10%': 0.629325, 'val_avg_loss_top10%': 4.156424, 'val_avg_loss_cos1': 0.894655, 'val_avg_loss_entropy': 2.165796, 'val_acc_std': 0.302998, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 0.928571, 'val_acc_min': 0.0, 'val_acc_max': 0.928571, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.928571, 'val_acc_cos1': 0.712711, 'val_acc_entropy': 1.785545, 'val_loss_std': 79.786325, 'val_loss_bottom_decile': 29.076349, 'val_loss_top_decile': 235.960587, 'val_loss_min': 8.810551, 'val_loss_max': 235.960587, 'val_loss_bottom10%': 8.810551, 'val_loss_top10%': 235.960587, 'val_loss_cos1': 0.804479, 'val_loss_entropy': 2.009907}}
2025-04-06 17:01:29,436 (server:353) INFO: Server: Starting evaluation at the end of round 13.
2025-04-06 17:01:29,436 (server:359) INFO: ----------- Starting a new training round (Round #14) -------------
2025-04-06 17:01:29,836 (client:354) INFO: {'Role': 'Client #9', 'Round': 14, 'Results_raw': {'train_avg_loss': 1.091147, 'train_total': 615, 'train_acc': 0.710569, 'train_loss': 671.05547}}
2025-04-06 17:01:29,971 (client:354) INFO: {'Role': 'Client #10', 'Round': 14, 'Results_raw': {'train_avg_loss': 1.550934, 'train_total': 420, 'train_acc': 0.504762, 'train_loss': 651.392185}}
2025-04-06 17:01:31,779 (client:354) INFO: {'Role': 'Client #8', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.699283, 'train_total': 6420, 'train_acc': 0.62757, 'train_loss': 4489.39384}}
2025-04-06 17:01:32,188 (client:354) INFO: {'Role': 'Client #1', 'Round': 14, 'Results_raw': {'train_avg_loss': 1.048551, 'train_total': 1435, 'train_acc': 0.578397, 'train_loss': 1504.670788}}
2025-04-06 17:01:32,322 (client:354) INFO: {'Role': 'Client #6', 'Round': 14, 'Results_raw': {'train_avg_loss': 1.074249, 'train_total': 390, 'train_acc': 0.592308, 'train_loss': 418.957127}}
2025-04-06 17:01:32,722 (client:354) INFO: {'Role': 'Client #4', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.767243, 'train_total': 1360, 'train_acc': 0.675, 'train_loss': 1043.450172}}
2025-04-06 17:01:33,825 (client:354) INFO: {'Role': 'Client #5', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.876324, 'train_total': 3865, 'train_acc': 0.641138, 'train_loss': 3386.99114}}
2025-04-06 17:01:34,567 (client:354) INFO: {'Role': 'Client #2', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.94329, 'train_total': 2560, 'train_acc': 0.584766, 'train_loss': 2414.823534}}
2025-04-06 17:01:34,742 (client:354) INFO: {'Role': 'Client #7', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.301656, 'train_total': 555, 'train_acc': 0.938739, 'train_loss': 167.419107}}
2025-04-06 17:01:35,390 (client:354) INFO: {'Role': 'Client #3', 'Round': 14, 'Results_raw': {'train_avg_loss': 0.817135, 'train_total': 2265, 'train_acc': 0.671523, 'train_loss': 1850.809855}}
2025-04-06 17:01:35,393 (server:615) INFO: {'Role': 'Server #', 'Round': 13, 'Results_weighted_avg': {'test_avg_loss': 1.897431, 'test_total': 50.0, 'test_acc': 0.298, 'test_loss': 146.143041, 'val_avg_loss': 1.92185, 'val_total': 49.6, 'val_acc': 0.27621, 'val_loss': 150.48136}, 'Results_avg': {'test_avg_loss': 2.174684, 'test_total': 50.0, 'test_acc': 0.294955, 'test_loss': 94.871535, 'val_avg_loss': 2.152793, 'val_total': 49.6, 'val_acc': 0.265958, 'val_loss': 95.323743}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.874712, 'test_avg_loss_bottom_decile': 1.238512, 'test_avg_loss_top_decile': 3.917301, 'test_avg_loss_min': 0.832227, 'test_avg_loss_max': 3.917301, 'test_avg_loss_bottom10%': 0.832227, 'test_avg_loss_top10%': 3.917301, 'test_avg_loss_cos1': 0.927763, 'test_avg_loss_entropy': 2.220403, 'test_acc_std': 0.263134, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.746212, 'test_acc_entropy': 1.868939, 'test_loss_std': 65.22866, 'test_loss_bottom_decile': 22.282885, 'test_loss_top_decile': 196.923463, 'test_loss_min': 10.818952, 'test_loss_max': 196.923463, 'test_loss_bottom10%': 10.818952, 'test_loss_top10%': 196.923463, 'test_loss_cos1': 0.824024, 'test_loss_entropy': 2.039461, 'val_avg_loss_std': 0.789582, 'val_avg_loss_bottom_decile': 1.348382, 'val_avg_loss_top_decile': 3.166614, 'val_avg_loss_min': 0.781532, 'val_avg_loss_max': 3.166614, 'val_avg_loss_bottom10%': 0.781532, 'val_avg_loss_top10%': 3.166614, 'val_avg_loss_cos1': 0.938845, 'val_avg_loss_entropy': 2.229641, 'val_acc_std': 0.261217, 'val_acc_bottom_decile': 0.0, 'val_acc_top_decile': 0.857143, 'val_acc_min': 0.0, 'val_acc_max': 0.857143, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.857143, 'val_acc_cos1': 0.713437, 'val_acc_entropy': 1.773084, 'val_loss_std': 68.551486, 'val_loss_bottom_decile': 25.285988, 'val_loss_top_decile': 215.741199, 'val_loss_min': 10.941445, 'val_loss_max': 215.741199, 'val_loss_bottom10%': 10.941445, 'val_loss_top10%': 215.741199, 'val_loss_cos1': 0.811864, 'val_loss_entropy': 2.022246}}
2025-04-06 17:01:35,397 (server:353) INFO: Server: Starting evaluation at the end of round 14.
2025-04-06 17:01:35,398 (server:359) INFO: ----------- Starting a new training round (Round #15) -------------
2025-04-06 17:01:37,294 (client:354) INFO: {'Role': 'Client #8', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.695216, 'train_total': 6420, 'train_acc': 0.630841, 'train_loss': 4463.284539}}
2025-04-06 17:01:37,418 (client:354) INFO: {'Role': 'Client #10', 'Round': 15, 'Results_raw': {'train_avg_loss': 1.506172, 'train_total': 420, 'train_acc': 0.578571, 'train_loss': 632.592374}}
2025-04-06 17:01:38,465 (client:354) INFO: {'Role': 'Client #5', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.845757, 'train_total': 3865, 'train_acc': 0.646054, 'train_loss': 3268.852155}}
2025-04-06 17:01:38,853 (client:354) INFO: {'Role': 'Client #1', 'Round': 15, 'Results_raw': {'train_avg_loss': 1.019881, 'train_total': 1435, 'train_acc': 0.580488, 'train_loss': 1463.528956}}
2025-04-06 17:01:39,536 (client:354) INFO: {'Role': 'Client #2', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.955603, 'train_total': 2560, 'train_acc': 0.575781, 'train_loss': 2446.344877}}
2025-04-06 17:01:39,716 (client:354) INFO: {'Role': 'Client #9', 'Round': 15, 'Results_raw': {'train_avg_loss': 1.043661, 'train_total': 615, 'train_acc': 0.718699, 'train_loss': 641.851811}}
2025-04-06 17:01:39,893 (client:354) INFO: {'Role': 'Client #7', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.306041, 'train_total': 555, 'train_acc': 0.935135, 'train_loss': 169.852883}}
2025-04-06 17:01:40,029 (client:354) INFO: {'Role': 'Client #6', 'Round': 15, 'Results_raw': {'train_avg_loss': 1.242807, 'train_total': 390, 'train_acc': 0.548718, 'train_loss': 484.694584}}
2025-04-06 17:01:40,680 (client:354) INFO: {'Role': 'Client #3', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.822228, 'train_total': 2265, 'train_acc': 0.689625, 'train_loss': 1862.347159}}
2025-04-06 17:01:41,066 (client:354) INFO: {'Role': 'Client #4', 'Round': 15, 'Results_raw': {'train_avg_loss': 0.81854, 'train_total': 1360, 'train_acc': 0.647059, 'train_loss': 1113.214199}}
2025-04-06 17:01:41,068 (server:615) INFO: {'Role': 'Server #', 'Round': 14, 'Results_weighted_avg': {'test_avg_loss': 2.102695, 'test_total': 50.0, 'test_acc': 0.322, 'test_loss': 150.834251, 'val_avg_loss': 2.128999, 'val_total': 49.6, 'val_acc': 0.314516, 'val_loss': 150.897904}, 'Results_avg': {'test_avg_loss': 2.424911, 'test_total': 50.0, 'test_acc': 0.312345, 'test_loss': 105.134752, 'val_avg_loss': 2.537061, 'val_total': 49.6, 'val_acc': 0.306214, 'val_loss': 105.598372}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 1.203035, 'test_avg_loss_bottom_decile': 1.036602, 'test_avg_loss_top_decile': 4.113981, 'test_avg_loss_min': 0.648427, 'test_avg_loss_max': 4.113981, 'test_avg_loss_bottom10%': 0.648427, 'test_avg_loss_top10%': 4.113981, 'test_avg_loss_cos1': 0.895815, 'test_avg_loss_entropy': 2.170261, 'test_acc_std': 0.290991, 'test_acc_bottom_decile': 0.027027, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.731676, 'test_acc_entropy': 1.844637, 'test_loss_std': 75.188545, 'test_loss_bottom_decile': 18.644803, 'test_loss_top_decile': 224.482864, 'test_loss_min': 8.429556, 'test_loss_max': 224.482864, 'test_loss_bottom10%': 8.429556, 'test_loss_top10%': 224.482864, 'test_loss_cos1': 0.813396, 'test_loss_entropy': 2.013908, 'val_avg_loss_std': 1.241477, 'val_avg_loss_bottom_decile': 1.087079, 'val_avg_loss_top_decile': 4.159853, 'val_avg_loss_min': 0.628202, 'val_avg_loss_max': 4.159853, 'val_avg_loss_bottom10%': 0.628202, 'val_avg_loss_top10%': 4.159853, 'val_avg_loss_cos1': 0.898226, 'val_avg_loss_entropy': 2.171228, 'val_acc_std': 0.299614, 'val_acc_bottom_decile': 0.029412, 'val_acc_top_decile': 0.928571, 'val_acc_min': 0.0, 'val_acc_max': 0.928571, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.928571, 'val_acc_cos1': 0.714768, 'val_acc_entropy': 1.816888, 'val_loss_std': 76.02459, 'val_loss_bottom_decile': 30.194813, 'val_loss_top_decile': 223.623597, 'val_loss_min': 8.79483, 'val_loss_max': 223.623597, 'val_loss_bottom10%': 8.79483, 'val_loss_top10%': 223.623597, 'val_loss_cos1': 0.811557, 'val_loss_entropy': 2.021227}}
2025-04-06 17:01:41,072 (server:353) INFO: Server: Starting evaluation at the end of round 15.
2025-04-06 17:01:41,073 (server:359) INFO: ----------- Starting a new training round (Round #16) -------------
2025-04-06 17:01:41,397 (client:354) INFO: {'Role': 'Client #10', 'Round': 16, 'Results_raw': {'train_avg_loss': 1.517727, 'train_total': 420, 'train_acc': 0.578571, 'train_loss': 637.445439}}
2025-04-06 17:01:42,462 (client:354) INFO: {'Role': 'Client #5', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.850843, 'train_total': 3865, 'train_acc': 0.640362, 'train_loss': 3288.508217}}
2025-04-06 17:01:43,172 (client:354) INFO: {'Role': 'Client #2', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.944004, 'train_total': 2560, 'train_acc': 0.585938, 'train_loss': 2416.64916}}
2025-04-06 17:01:43,581 (client:354) INFO: {'Role': 'Client #1', 'Round': 16, 'Results_raw': {'train_avg_loss': 1.064235, 'train_total': 1435, 'train_acc': 0.58885, 'train_loss': 1527.177161}}
2025-04-06 17:01:43,756 (client:354) INFO: {'Role': 'Client #9', 'Round': 16, 'Results_raw': {'train_avg_loss': 1.073909, 'train_total': 615, 'train_acc': 0.717073, 'train_loss': 660.454174}}
2025-04-06 17:01:45,759 (client:354) INFO: {'Role': 'Client #8', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.68701, 'train_total': 6420, 'train_acc': 0.638162, 'train_loss': 4410.604467}}
2025-04-06 17:01:45,946 (client:354) INFO: {'Role': 'Client #7', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.272671, 'train_total': 555, 'train_acc': 0.945946, 'train_loss': 151.332536}}
2025-04-06 17:01:46,638 (client:354) INFO: {'Role': 'Client #3', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.842963, 'train_total': 2265, 'train_acc': 0.686534, 'train_loss': 1909.312114}}
2025-04-06 17:01:47,057 (client:354) INFO: {'Role': 'Client #4', 'Round': 16, 'Results_raw': {'train_avg_loss': 0.783865, 'train_total': 1360, 'train_acc': 0.679412, 'train_loss': 1066.056507}}
2025-04-06 17:01:47,218 (client:354) INFO: {'Role': 'Client #6', 'Round': 16, 'Results_raw': {'train_avg_loss': 1.240988, 'train_total': 390, 'train_acc': 0.571795, 'train_loss': 483.985429}}
2025-04-06 17:01:47,220 (server:615) INFO: {'Role': 'Server #', 'Round': 15, 'Results_weighted_avg': {'test_avg_loss': 2.206821, 'test_total': 50.0, 'test_acc': 0.392, 'test_loss': 154.590504, 'val_avg_loss': 2.180801, 'val_total': 49.6, 'val_acc': 0.399194, 'val_loss': 152.096505}, 'Results_avg': {'test_avg_loss': 2.547964, 'test_total': 50.0, 'test_acc': 0.34394, 'test_loss': 110.341037, 'val_avg_loss': 2.588275, 'val_total': 49.6, 'val_acc': 0.369035, 'val_loss': 108.167713}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 1.377192, 'test_avg_loss_bottom_decile': 0.930648, 'test_avg_loss_top_decile': 4.526336, 'test_avg_loss_min': 0.536921, 'test_avg_loss_max': 4.526336, 'test_avg_loss_bottom10%': 0.536921, 'test_avg_loss_top10%': 4.526336, 'test_avg_loss_cos1': 0.879719, 'test_avg_loss_entropy': 2.143824, 'test_acc_std': 0.309509, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.743334, 'test_acc_entropy': 1.834077, 'test_loss_std': 82.289058, 'test_loss_bottom_decile': 18.49684, 'test_loss_top_decile': 240.732087, 'test_loss_min': 6.979973, 'test_loss_max': 240.732087, 'test_loss_bottom10%': 6.979973, 'test_loss_top10%': 240.732087, 'test_loss_cos1': 0.801625, 'test_loss_entropy': 1.993694, 'val_avg_loss_std': 1.320139, 'val_avg_loss_bottom_decile': 0.999501, 'val_avg_loss_top_decile': 4.301726, 'val_avg_loss_min': 0.557789, 'val_avg_loss_max': 4.301726, 'val_avg_loss_bottom10%': 0.557789, 'val_avg_loss_top10%': 4.301726, 'val_avg_loss_cos1': 0.890819, 'val_avg_loss_entropy': 2.159012, 'val_acc_std': 0.292771, 'val_acc_bottom_decile': 0.048387, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.029412, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.029412, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.783406, 'val_acc_entropy': 1.980495, 'val_loss_std': 80.236975, 'val_loss_bottom_decile': 31.370398, 'val_loss_top_decile': 239.547954, 'val_loss_min': 7.809052, 'val_loss_max': 239.547954, 'val_loss_bottom10%': 7.809052, 'val_loss_top10%': 239.547954, 'val_loss_cos1': 0.803157, 'val_loss_entropy': 2.007486}}
2025-04-06 17:01:47,225 (server:353) INFO: Server: Starting evaluation at the end of round 16.
2025-04-06 17:01:47,225 (server:359) INFO: ----------- Starting a new training round (Round #17) -------------
2025-04-06 17:01:47,618 (client:354) INFO: {'Role': 'Client #6', 'Round': 17, 'Results_raw': {'train_avg_loss': 1.171611, 'train_total': 390, 'train_acc': 0.576923, 'train_loss': 456.928179}}
2025-04-06 17:01:47,757 (client:354) INFO: {'Role': 'Client #10', 'Round': 17, 'Results_raw': {'train_avg_loss': 1.415105, 'train_total': 420, 'train_acc': 0.628571, 'train_loss': 594.344223}}
2025-04-06 17:01:47,939 (client:354) INFO: {'Role': 'Client #9', 'Round': 17, 'Results_raw': {'train_avg_loss': 1.083603, 'train_total': 615, 'train_acc': 0.733333, 'train_loss': 666.41567}}
2025-04-06 17:01:48,351 (client:354) INFO: {'Role': 'Client #1', 'Round': 17, 'Results_raw': {'train_avg_loss': 1.022089, 'train_total': 1435, 'train_acc': 0.590941, 'train_loss': 1466.698196}}
2025-04-06 17:01:48,547 (client:354) INFO: {'Role': 'Client #7', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.309641, 'train_total': 555, 'train_acc': 0.938739, 'train_loss': 171.850594}}
2025-04-06 17:01:49,330 (client:354) INFO: {'Role': 'Client #2', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.936869, 'train_total': 2560, 'train_acc': 0.583203, 'train_loss': 2398.383623}}
2025-04-06 17:01:51,208 (client:354) INFO: {'Role': 'Client #8', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.685297, 'train_total': 6420, 'train_acc': 0.641277, 'train_loss': 4399.606916}}
2025-04-06 17:01:52,384 (client:354) INFO: {'Role': 'Client #5', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.808358, 'train_total': 3865, 'train_acc': 0.675291, 'train_loss': 3124.302534}}
2025-04-06 17:01:52,814 (client:354) INFO: {'Role': 'Client #4', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.77657, 'train_total': 1360, 'train_acc': 0.672794, 'train_loss': 1056.135516}}
2025-04-06 17:01:53,506 (client:354) INFO: {'Role': 'Client #3', 'Round': 17, 'Results_raw': {'train_avg_loss': 0.797836, 'train_total': 2265, 'train_acc': 0.705519, 'train_loss': 1807.099648}}
2025-04-06 17:01:53,508 (server:615) INFO: {'Role': 'Server #', 'Round': 16, 'Results_weighted_avg': {'test_avg_loss': 1.941085, 'test_total': 50.0, 'test_acc': 0.412, 'test_loss': 143.222476, 'val_avg_loss': 2.008097, 'val_total': 49.6, 'val_acc': 0.385081, 'val_loss': 147.437458}, 'Results_avg': {'test_avg_loss': 2.267163, 'test_total': 50.0, 'test_acc': 0.359113, 'test_loss': 97.054259, 'val_avg_loss': 2.363359, 'val_total': 49.6, 'val_acc': 0.330625, 'val_loss': 99.601607}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.985723, 'test_avg_loss_bottom_decile': 1.083479, 'test_avg_loss_top_decile': 3.987126, 'test_avg_loss_min': 0.947969, 'test_avg_loss_max': 3.987126, 'test_avg_loss_bottom10%': 0.947969, 'test_avg_loss_top10%': 3.987126, 'test_avg_loss_cos1': 0.91707, 'test_avg_loss_entropy': 2.205927, 'test_acc_std': 0.248175, 'test_acc_bottom_decile': 0.111111, 'test_acc_top_decile': 0.714286, 'test_acc_min': 0.0, 'test_acc_max': 0.714286, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.714286, 'test_acc_cos1': 0.822665, 'test_acc_entropy': 2.02137, 'test_loss_std': 66.448351, 'test_loss_bottom_decile': 20.441084, 'test_loss_top_decile': 188.566088, 'test_loss_min': 12.323599, 'test_loss_max': 188.566088, 'test_loss_bottom10%': 12.323599, 'test_loss_top10%': 188.566088, 'test_loss_cos1': 0.825138, 'test_loss_entropy': 2.040303, 'val_avg_loss_std': 0.934982, 'val_avg_loss_bottom_decile': 1.143326, 'val_avg_loss_top_decile': 3.535711, 'val_avg_loss_min': 0.894477, 'val_avg_loss_max': 3.535711, 'val_avg_loss_bottom10%': 0.894477, 'val_avg_loss_top10%': 3.535711, 'val_avg_loss_cos1': 0.929876, 'val_avg_loss_entropy': 2.217863, 'val_acc_std': 0.252342, 'val_acc_bottom_decile': 0.080645, 'val_acc_top_decile': 0.857143, 'val_acc_min': 0.0, 'val_acc_max': 0.857143, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.857143, 'val_acc_cos1': 0.794925, 'val_acc_entropy': 1.98164, 'val_loss_std': 68.383567, 'val_loss_bottom_decile': 31.363718, 'val_loss_top_decile': 191.983086, 'val_loss_min': 12.522677, 'val_loss_max': 191.983086, 'val_loss_bottom10%': 12.522677, 'val_loss_top10%': 191.983086, 'val_loss_cos1': 0.824399, 'val_loss_entropy': 2.044898}}
2025-04-06 17:01:53,513 (server:353) INFO: Server: Starting evaluation at the end of round 17.
2025-04-06 17:01:53,513 (server:359) INFO: ----------- Starting a new training round (Round #18) -------------
2025-04-06 17:01:55,818 (client:354) INFO: {'Role': 'Client #8', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.682032, 'train_total': 6420, 'train_acc': 0.644081, 'train_loss': 4378.643465}}
2025-04-06 17:01:56,005 (client:354) INFO: {'Role': 'Client #9', 'Round': 18, 'Results_raw': {'train_avg_loss': 1.140265, 'train_total': 615, 'train_acc': 0.666667, 'train_loss': 701.263186}}
2025-04-06 17:01:56,158 (client:354) INFO: {'Role': 'Client #6', 'Round': 18, 'Results_raw': {'train_avg_loss': 1.20361, 'train_total': 390, 'train_acc': 0.530769, 'train_loss': 469.407898}}
2025-04-06 17:01:56,891 (client:354) INFO: {'Role': 'Client #2', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.910309, 'train_total': 2560, 'train_acc': 0.578125, 'train_loss': 2330.390533}}
2025-04-06 17:01:57,316 (client:354) INFO: {'Role': 'Client #1', 'Round': 18, 'Results_raw': {'train_avg_loss': 1.026469, 'train_total': 1435, 'train_acc': 0.586063, 'train_loss': 1472.983101}}
2025-04-06 17:01:57,458 (client:354) INFO: {'Role': 'Client #10', 'Round': 18, 'Results_raw': {'train_avg_loss': 1.4902, 'train_total': 420, 'train_acc': 0.533333, 'train_loss': 625.883894}}
2025-04-06 17:01:57,860 (client:354) INFO: {'Role': 'Client #4', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.778415, 'train_total': 1360, 'train_acc': 0.667647, 'train_loss': 1058.64386}}
2025-04-06 17:01:59,005 (client:354) INFO: {'Role': 'Client #5', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.886621, 'train_total': 3865, 'train_acc': 0.625873, 'train_loss': 3426.791833}}
2025-04-06 17:01:59,722 (client:354) INFO: {'Role': 'Client #3', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.765663, 'train_total': 2265, 'train_acc': 0.705077, 'train_loss': 1734.225614}}
2025-04-06 17:01:59,905 (client:354) INFO: {'Role': 'Client #7', 'Round': 18, 'Results_raw': {'train_avg_loss': 0.303532, 'train_total': 555, 'train_acc': 0.933333, 'train_loss': 168.460012}}
2025-04-06 17:01:59,908 (server:615) INFO: {'Role': 'Server #', 'Round': 17, 'Results_weighted_avg': {'test_avg_loss': 1.966086, 'test_total': 50.0, 'test_acc': 0.342, 'test_loss': 149.350788, 'val_avg_loss': 1.975292, 'val_total': 49.6, 'val_acc': 0.320565, 'val_loss': 151.080642}, 'Results_avg': {'test_avg_loss': 2.273033, 'test_total': 50.0, 'test_acc': 0.303168, 'test_loss': 98.304316, 'val_avg_loss': 2.270078, 'val_total': 49.6, 'val_acc': 0.292617, 'val_loss': 97.97446}, 'Results_fairness': {'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 0.927271, 'test_avg_loss_bottom_decile': 1.23214, 'test_avg_loss_top_decile': 4.00652, 'test_avg_loss_min': 0.880436, 'test_avg_loss_max': 4.00652, 'test_avg_loss_bottom10%': 0.880436, 'test_avg_loss_top10%': 4.00652, 'test_avg_loss_cos1': 0.925919, 'test_avg_loss_entropy': 2.217414, 'test_acc_std': 0.232097, 'test_acc_bottom_decile': 0.054054, 'test_acc_top_decile': 0.692308, 'test_acc_min': 0.0, 'test_acc_max': 0.692308, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.692308, 'test_acc_cos1': 0.794025, 'test_acc_entropy': 1.965756, 'test_loss_std': 67.202377, 'test_loss_bottom_decile': 23.961346, 'test_loss_top_decile': 195.910274, 'test_loss_min': 11.445674, 'test_loss_max': 195.910274, 'test_loss_bottom10%': 11.445674, 'test_loss_top10%': 195.910274, 'test_loss_cos1': 0.825536, 'test_loss_entropy': 2.041961, 'val_avg_loss_std': 0.826801, 'val_avg_loss_bottom_decile': 1.314899, 'val_avg_loss_top_decile': 3.279278, 'val_avg_loss_min': 0.81451, 'val_avg_loss_max': 3.279278, 'val_avg_loss_bottom10%': 0.81451, 'val_avg_loss_top10%': 3.279278, 'val_avg_loss_cos1': 0.939618, 'val_avg_loss_entropy': 2.229449, 'val_acc_std': 0.249082, 'val_acc_bottom_decile': 0.029412, 'val_acc_top_decile': 0.857143, 'val_acc_min': 0.0, 'val_acc_max': 0.857143, 'val_acc_bottom10%': 0.0, 'val_acc_top10%': 0.857143, 'val_acc_cos1': 0.76148, 'val_acc_entropy': 1.926854, 'val_loss_std': 68.293078, 'val_loss_bottom_decile': 28.989613, 'val_loss_top_decile': 210.383827, 'val_loss_min': 11.403136, 'val_loss_max': 210.383827, 'val_loss_bottom10%': 11.403136, 'val_loss_top10%': 210.383827, 'val_loss_cos1': 0.820367, 'val_loss_entropy': 2.038482}}
2025-04-06 17:01:59,911 (server:420) INFO: Server: Final evaluation is finished! Starting merging results.
2025-04-06 17:01:59,911 (server:546) INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {'test_loss': 6.170902, 'test_avg_loss': 0.474685, 'test_total': 9.0, 'test_acc': 1.0, 'val_avg_loss': 0.629325, 'val_total': 10.0, 'val_acc': 0.928571, 'val_loss': 8.810551}, 'client_summarized_weighted_avg': {'test_loss': 137.892465, 'test_avg_loss': 1.786916, 'test_total': 50.0, 'test_acc': 0.294, 'val_avg_loss': 1.790836, 'val_total': 49.6, 'val_acc': 0.294355, 'val_loss': 138.360905}, 'client_summarized_avg': {'test_loss': 89.306591, 'test_avg_loss': 1.947118, 'test_total': 50.0, 'test_acc': 0.297786, 'val_avg_loss': 1.96334, 'val_total': 49.6, 'val_acc': 0.284851, 'val_loss': 88.576612}, 'client_summarized_fairness': {'test_loss_entropy': 1.993694, 'test_loss_cos1': 0.801625, 'test_loss_top10%': 240.732087, 'test_loss_bottom10%': 6.979973, 'test_loss_max': 240.732087, 'test_loss_min': 6.979973, 'test_loss_top_decile': 240.732087, 'test_loss_bottom_decile': 18.49684, 'test_loss_std': 82.289058, 'test_total': 50.0, 'val_total': 49.6, 'test_avg_loss_std': 1.377192, 'test_avg_loss_bottom_decile': 0.930648, 'test_avg_loss_top_decile': 4.526336, 'test_avg_loss_min': 0.536921, 'test_avg_loss_max': 4.526336, 'test_avg_loss_bottom10%': 0.536921, 'test_avg_loss_top10%': 4.526336, 'test_avg_loss_cos1': 0.879719, 'test_avg_loss_entropy': 2.143824, 'test_acc_std': 0.309509, 'test_acc_bottom_decile': 0.0, 'test_acc_top_decile': 0.846154, 'test_acc_min': 0.0, 'test_acc_max': 0.846154, 'test_acc_bottom10%': 0.0, 'test_acc_top10%': 0.846154, 'test_acc_cos1': 0.743334, 'test_acc_entropy': 1.834077, 'val_avg_loss_std': 1.320139, 'val_avg_loss_bottom_decile': 0.999501, 'val_avg_loss_top_decile': 4.301726, 'val_avg_loss_min': 0.557789, 'val_avg_loss_max': 4.301726, 'val_avg_loss_bottom10%': 0.557789, 'val_avg_loss_top10%': 4.301726, 'val_avg_loss_cos1': 0.890819, 'val_avg_loss_entropy': 2.159012, 'val_acc_std': 0.292771, 'val_acc_bottom_decile': 0.048387, 'val_acc_top_decile': 1.0, 'val_acc_min': 0.029412, 'val_acc_max': 1.0, 'val_acc_bottom10%': 0.029412, 'val_acc_top10%': 1.0, 'val_acc_cos1': 0.783406, 'val_acc_entropy': 1.980495, 'val_loss_std': 80.236975, 'val_loss_bottom_decile': 31.370398, 'val_loss_top_decile': 239.547954, 'val_loss_min': 7.809052, 'val_loss_max': 239.547954, 'val_loss_bottom10%': 7.809052, 'val_loss_top10%': 239.547954, 'val_loss_cos1': 0.803157, 'val_loss_entropy': 2.007486}}}
2025-04-06 17:01:59,916 (server:565) INFO: {'Role': 'Client #1', 'Round': 501, 'Results_raw': {'test_avg_loss': 1.983438, 'test_total': 37, 'test_acc': 0.054054, 'test_loss': 73.387204, 'val_avg_loss': 2.096991, 'val_total': 34, 'val_acc': 0.147059, 'val_loss': 71.297692}}
2025-04-06 17:01:59,917 (server:565) INFO: {'Role': 'Client #2', 'Round': 501, 'Results_raw': {'test_avg_loss': 2.779238, 'test_total': 62, 'test_acc': 0.112903, 'test_loss': 172.312734, 'val_avg_loss': 2.820243, 'val_total': 62, 'val_acc': 0.112903, 'val_loss': 174.855073}}
2025-04-06 17:01:59,918 (server:565) INFO: {'Role': 'Client #3', 'Round': 501, 'Results_raw': {'test_avg_loss': 2.944601, 'test_total': 59, 'test_acc': 0.20339, 'test_loss': 173.731458, 'val_avg_loss': 2.948229, 'val_total': 58, 'val_acc': 0.241379, 'val_loss': 170.997307}}
2025-04-06 17:01:59,919 (server:565) INFO: {'Role': 'Client #4', 'Round': 501, 'Results_raw': {'test_avg_loss': 3.206634, 'test_total': 35, 'test_acc': 0.0, 'test_loss': 112.232204, 'val_avg_loss': 3.279278, 'val_total': 34, 'val_acc': 0.029412, 'val_loss': 111.495446}}
2025-04-06 17:01:59,920 (server:565) INFO: {'Role': 'Client #5', 'Round': 501, 'Results_raw': {'test_avg_loss': 1.526218, 'test_total': 98, 'test_acc': 0.510204, 'test_loss': 149.569406, 'val_avg_loss': 1.376885, 'val_total': 97, 'val_acc': 0.525773, 'val_loss': 133.557867}}
2025-04-06 17:01:59,920 (server:565) INFO: {'Role': 'Client #6', 'Round': 501, 'Results_raw': {'test_avg_loss': 4.00652, 'test_total': 9, 'test_acc': 0.111111, 'test_loss': 36.058678, 'val_avg_loss': 2.898961, 'val_total': 10, 'val_acc': 0.2, 'val_loss': 28.989613}}
2025-04-06 17:01:59,921 (server:565) INFO: {'Role': 'Client #7', 'Round': 501, 'Results_raw': {'test_avg_loss': 0.880436, 'test_total': 13, 'test_acc': 0.692308, 'test_loss': 11.445674, 'val_avg_loss': 0.81451, 'val_total': 14, 'val_acc': 0.857143, 'val_loss': 11.403136}}
2025-04-06 17:01:59,922 (server:565) INFO: {'Role': 'Client #8', 'Round': 501, 'Results_raw': {'test_avg_loss': 1.23214, 'test_total': 159, 'test_acc': 0.490566, 'test_loss': 195.910274, 'val_avg_loss': 1.314899, 'val_total': 160, 'val_acc': 0.375, 'val_loss': 210.383827}}
2025-04-06 17:01:59,924 (server:565) INFO: {'Role': 'Client #9', 'Round': 501, 'Results_raw': {'test_avg_loss': 1.711525, 'test_total': 14, 'test_acc': 0.571429, 'test_loss': 23.961346, 'val_avg_loss': 2.021214, 'val_total': 16, 'val_acc': 0.4375, 'val_loss': 32.33942}}
2025-04-06 17:01:59,924 (server:565) INFO: {'Role': 'Client #10', 'Round': 501, 'Results_raw': {'test_avg_loss': 2.459584, 'test_total': 14, 'test_acc': 0.285714, 'test_loss': 34.434183, 'val_avg_loss': 3.129565, 'val_total': 11, 'val_acc': 0.0, 'val_loss': 34.425218}}
2025-04-06 17:01:59,925 (monitor:173) INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 2.049938, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 532752, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.049704, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,926 (client:574) INFO: ================= client 1 received finish message =================
2025-04-06 17:01:59,927 (monitor:173) INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 2.049804, 'total_model_size': 10439, 'total_flops': 12214720.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.049788, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,928 (client:574) INFO: ================= client 2 received finish message =================
2025-04-06 17:01:59,928 (monitor:173) INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 2.048355, 'total_model_size': 10439, 'total_flops': 21790720.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.048321, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,929 (client:574) INFO: ================= client 3 received finish message =================
2025-04-06 17:01:59,930 (monitor:173) INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 2.047505, 'total_model_size': 10439, 'total_flops': 19279680.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.047438, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,931 (client:574) INFO: ================= client 4 received finish message =================
2025-04-06 17:01:59,931 (monitor:173) INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 2.046655, 'total_model_size': 10439, 'total_flops': 11576320.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.046571, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,932 (client:574) INFO: ================= client 5 received finish message =================
2025-04-06 17:01:59,932 (monitor:173) INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 2.045811, 'total_model_size': 10439, 'total_flops': 32898880.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.045711, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,933 (client:574) INFO: ================= client 6 received finish message =================
2025-04-06 17:01:59,934 (monitor:173) INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 2.045011, 'total_model_size': 10439, 'total_flops': 3319680.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.044877, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,935 (client:574) INFO: ================= client 7 received finish message =================
2025-04-06 17:01:59,935 (monitor:173) INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 2.044161, 'total_model_size': 10439, 'total_flops': 4724160.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.044011, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,936 (client:574) INFO: ================= client 8 received finish message =================
2025-04-06 17:01:59,936 (monitor:173) INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 2.043361, 'total_model_size': 10439, 'total_flops': 54647040.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.043194, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,937 (client:574) INFO: ================= client 9 received finish message =================
2025-04-06 17:01:59,938 (monitor:173) INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 2.042428, 'total_model_size': 10439, 'total_flops': 5234880.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.042228, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,938 (client:574) INFO: ================= client 10 received finish message =================
2025-04-06 17:01:59,939 (monitor:173) INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 2.041362, 'total_model_size': 10439, 'total_flops': 3575040.0, 'total_upload_bytes': 0, 'total_download_bytes': 81160, 'global_convergence_round': 18, 'local_convergence_round': 0, 'global_convergence_time_minutes': 2.041145, 'local_convergence_time_minutes': 0}
2025-04-06 17:01:59,940 (monitor:338) INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one
2025-04-06 17:01:59,965 (monitor:246) INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 2.045853, 'sys_avg/total_model_size': '9.27K', 'sys_avg/total_flops': '14.67M', 'sys_avg/total_upload_bytes': '0.0', 'sys_avg/total_download_bytes': '119.35K', 'sys_avg/global_convergence_round': 18.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 2.045726, 'sys_avg/local_convergence_time_minutes': 0.0})
2025-04-06 17:01:59,966 (monitor:249) INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.002757, 'sys_std/total_model_size': '2.93K', 'sys_std/total_flops': '14.85M', 'sys_std/total_upload_bytes': '0.0', 'sys_std/total_download_bytes': '126.78K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.002796, 'sys_std/local_convergence_time_minutes': 0.0})
